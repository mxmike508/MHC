{
  "name": "Master Workflow v5",
  "nodes": [
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT *\nFROM conversation_history\nWHERE\n  session_id = $1\n  AND id > $2;",
        "options": {
          "queryReplacement": "={{ [ $('Trigger: Receive Session ID').first().json.body.chat_session_id, $('Set: Watermark Value').first().json.highWaterMark ] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -4032,
        -3888
      ],
      "id": "5aeea5b4-5b38-4d87-821a-e524a18c7cc0",
      "name": "DB: Get Conversation History",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const items = $('DB: Get Conversation History').all();\nlet assembledTranscript = \"\";\n\nfor (const item of items) {\n  // Only process items that have a role and content\n  if (item.json.role && item.json.content) {\n    const role = item.json.role;\n    const content = item.json.content;\n    const formattedRole = role.charAt(0).toUpperCase() + role.slice(1);\n    assembledTranscript += `${formattedRole}: ${content}\\n`;\n  }\n}\n\n// If empty, return benign output; downstream can decide to no-op.\nif (assembledTranscript.trim() === \"\") {\n  return [{ json: { assembledTranscript: \"\" } }];\n}\n\nreturn [{ json: { assembledTranscript: assembledTranscript.trim() } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3360,
        -3888
      ],
      "id": "e5b75f4f-547a-460e-a490-9e8304504095",
      "name": "Format: Assemble Transcript",
      "alwaysOutputData": false
    },
    {
      "parameters": {
        "jsCode": "// Get the transcript from the previous node\nconst transcript = $input.item.json.assembledTranscript;\n\n// --- CORRECTED PROMPT ---\n// This new prompt is more lenient and will capture more information.\nconst system_prompt = `You are a meticulous data extraction engine. Your sole purpose is to convert a conversation transcript into a structured JSON object containing a list of key informational statements.\n\nRules:\n- Your output MUST be a JSON object with a single key: \"facts\".\n- The \"facts\" key must contain an array of strings.\n- Each string should be a key piece of information, a specific detail, or a factual statement.\n- Extract informational content from both the User and the Assistant.\n- IGNORE simple pleasantries (hello, thanks) and questions that do not contain information.\n- If no new information is found, the \"facts\" array MUST be empty: [].`;\n\n// Build the complete JSON body for the OpenAI API call\nconst requestBody = {\n  \"model\": \"gpt-4o\",\n  \"response_format\": { \"type\": \"json_object\" },\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": system_prompt\n    },\n    {\n      \"role\": \"user\",\n      \"content\": transcript\n    }\n  ]\n};\n\n// Return the entire object for the next node\nreturn requestBody;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3136,
        -3888
      ],
      "id": "23b7e82c-3449-4664-9704-adb388e8aadb",
      "name": "Build: OpenAI Request Body"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "=application/json",
        "body": "={{ JSON.stringify($json) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2912,
        -3888
      ],
      "id": "c88110f9-176f-4eae-8c64-cbf6697fbb89",
      "name": "Execute: OpenAI API Call",
      "credentials": {
        "openAiApi": {
          "id": "XWtCAAEVWi0CPB0c",
          "name": "OpenAi (Chat Completions)"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT COALESCE(\n  (SELECT last_processed_message_id FROM memory_commit_log WHERE session_id = $1),\n  0\n) as high_water_mark;",
        "options": {
          "queryReplacement": "={{ $('Trigger: Receive Session ID').first().json.body.chat_session_id }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -4464,
        -3888
      ],
      "id": "3e37726c-428a-488c-99df-818c23311e5d",
      "name": "DB: Get High-Water Mark",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "28e6b89f-2ac1-420d-9774-231e6d7834c3",
              "name": "highWaterMark",
              "value": "={{ $json.high_water_mark ?? 0 }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -4240,
        -3888
      ],
      "id": "89903a4d-feab-4062-adfd-daace77ada42",
      "name": "Set: Watermark Value"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b2c6aead-ea59-4a6e-9101-e1f9541c8d8e",
              "name": "summary_text",
              "value": "={{ $json.choices[0].message.content }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2704,
        -3888
      ],
      "id": "7b5e22f8-6e14-4d67-b9eb-5cf958b59fab",
      "name": "Set: Extracted Summary"
    },
    {
      "parameters": {
        "jsCode": "// Count number of distilled facts for commit status / toast.\nconst s = $('Set: Extracted Summary').first().json.summary_text;\nlet count = 0;\ntry { const obj = JSON.parse(s); if (Array.isArray(obj.facts)) count = obj.facts.length; } catch (e) {}\nreturn { count };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1600,
        -3792
      ],
      "id": "3289581e-a922-4a35-a77c-bbfe9df0c800",
      "name": "Count Facts"
    },
    {
      "parameters": {
        "jsCode": "// This node takes the JSON string from the AI, extracts the facts,\n// and returns each fact as a separate item to be embedded.\n\n// Get the summary_text which contains a JSON string of facts.\nconst summaryJsonString = $input.item.json.summary_text;\n\n// Parse the string to get the actual JSON object.\nconst summaryObject = JSON.parse(summaryJsonString);\n\n// Get the array of facts from the object.\nconst factsArray = summaryObject.facts;\n\n// If there are no facts, return an empty array to stop the workflow.\nif (factsArray.length === 0) {\n  return [];\n}\n\n// Return each fact as a separate item, with the correct key.\nreturn factsArray.map(fact => {\n  return {\n    json: {\n      \"chunk_text_for_embedding\": fact\n    }\n  }\n});"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2480,
        -4000
      ],
      "id": "088b83ae-908d-40f7-a00c-ec3938c13968",
      "name": "Chunk: Distilled Summary"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO rag_store (project_id, session_id, original_content, role, embedding)\nVALUES ($1, $2, $3, $4, '{{ JSON.stringify($json.embedding) }}');",
        "options": {
          "queryReplacement": "={{ $json.project_id }},{{ $json.session_id }},{{ $json.original_content }},{{ $json.role }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1824,
        -4000
      ],
      "id": "9a05a645-8fa8-48b0-a9dc-566f488641c7",
      "name": "DB: Insert Embedding1",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO memory_commit_log (session_id, last_processed_message_id, processed_at)\nVALUES ($1, $2, NOW())\nON CONFLICT (session_id)\nDO UPDATE SET\n    last_processed_message_id = EXCLUDED.last_processed_message_id,\n    processed_at = NOW();",
        "options": {
          "queryReplacement": "={{ $('Trigger: Receive Session ID').first().json.body.chat_session_id }},{{ $('Calculate New High-Water Mark').first().json.new_high_water_mark }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1600,
        -4000
      ],
      "id": "9941234a-ccc2-43d8-bb1c-36f84fd6f531",
      "name": "DB: Update High-Water Mark",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "71077881-f2db-46b6-8537-c6fece3d5296",
              "leftValue": "",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "equals",
                "name": "filter.operator.equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3584,
        -3888
      ],
      "id": "2a7f42e6-c762-40e3-b11b-dcba97d2a647",
      "name": "IF: New Messages Found?"
    },
    {
      "parameters": {
        "jsCode": "// This node finds the highest 'id' from the incoming messages.\nconst items = $input.all();\nlet maxId = 0;\n\n// If there are no items, the watermark is 0.\nif (items.length === 0) {\n  return [{ json: { new_high_water_mark: maxId } }];\n}\n\n// Find the highest id in the list of messages.\nfor (const item of items) {\n  if (item.json.id > maxId) {\n    maxId = item.json.id;\n  }\n}\n\n// Return the single highest value.\nreturn [{ json: { new_high_water_mark: maxId } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3808,
        -3888
      ],
      "id": "8ff0366d-0b29-4e42-82f5-c584c2284209",
      "name": "Calculate New High-Water Mark"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={ \"model\": \"text-embedding-3-small\", \"input\": \"{{ $json.chunk_text_for_embedding }}\" }",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2256,
        -4000
      ],
      "id": "088289bb-7856-44f2-93d0-7f1311234197",
      "name": "API: Create Embeddings (HTTP) node",
      "credentials": {
        "openAiApi": {
          "id": "XWtCAAEVWi0CPB0c",
          "name": "OpenAi (Chat Completions)"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// This is the corrected final assembly. It pulls data from all necessary\n// previous nodes to create the complete payload for the database.\n\n// 1. Get the new embedding.\nconst embedding = $json.data[0].embedding;\n\n// 2. Get the summary text.\nconst summaryData = $('Set: Extracted Summary').first().json;\nconst summaryText = summaryData.summary_text;\n\n// 3. Get the project ID.\nconst projectData = $('Get Project ID').first().json;\nconst projectId = projectData.project_id;\n\n// 4. Get the RAG session ID to scope long-term memory writes.\nconst triggerData = $('Trigger: Receive Session ID').first().json;\nconst sessionId = triggerData.body.rag_session_id;\n\n// 5. Get the new high-water mark we just calculated.\nconst watermarkData = $('Calculate New High-Water Mark').first().json;\nconst newHighWaterMark = watermarkData.new_high_water_mark;\n\n// 6. Build the final, complete payload with EVERYTHING needed.\nconst finalPayload = {\n  project_id: projectId,\n  session_id: sessionId,\n  original_content: summaryText,\n  role: 'summary',\n  embedding: embedding,\n  new_high_water_mark: newHighWaterMark\n};\n\nreturn finalPayload;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2032,
        -4000
      ],
      "id": "b5d19e68-2d3b-49fc-a578-b83ca06ef4f0",
      "name": "Merge Embedding with Original Data"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT xata_id AS project_id FROM project_contexts WHERE chat_session_id = $1",
        "options": {
          "queryReplacement": "=[   {{ $('Trigger: Receive Session ID').first().json.body.chat_session_id }} ]"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -4688,
        -3888
      ],
      "id": "421505f9-1ad3-4434-ab87-827a423fcec1",
      "name": "Get Project ID",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "6c1ce608-2f7a-457b-9afc-f0be5ef4bd4c",
        "responseMode": "responseNode",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              },
              {
                "name": "Access-Control-Allow-Methods",
                "value": "POST, OPTIONS"
              },
              {
                "name": "Access-Control-Allow-Headers",
                "value": "Content-Type, Authorization"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4912,
        -3888
      ],
      "id": "6533bbc8-58f2-41a8-9f36-10caff1732a4",
      "name": "Trigger: Receive Session ID",
      "webhookId": "5ffef26b-622a-4295-9151-4b3f677f479f",
      "options": {
        "allowedOrigins": "*",
        "responseHeaders": {
          "entries": [
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            },
            {
              "name": "Access-Control-Allow-Methods",
              "value": "POST, OPTIONS"
            },
            {
              "name": "Access-Control-Allow-Headers",
              "value": "Content-Type, Authorization"
            }
          ]
        }
      }
    },
    {
      "parameters": {
        "content": "## System Documentation: Context Distillation & Indexing\n\n\nWorkflow Name: System: Context Distillation & Indexing for Documentation\nSource File: System__Context_Distillation___Indexing_for_Documentation.json\nProject Lead: Mike Holland\nSystem Architect: Gemini Pro\n1. Overall Goal\nThis workflow serves as the dedicated \"Commit to Memory\" function for the Chat 8 UI. Its purpose is to solve the problem of limited context windows in LLMs by creating a persistent, long-term memory store. It is triggered manually by the user, reads the recent, unprocessed conversation history for a given session, uses a powerful AI model to distill that conversation into a set of atomic facts, generates vector embeddings for those facts, and saves them to the rag_store database.\n2. Key Components & Architecture\nTrigger: A unique n8n Webhook (...6c1ce608...) listens for POST requests from the Chat 8 UI's \"Commit to Memory\" button.\nDatabase: It interacts with three key tables in the Postgres database: conversation_history (to read new messages), memory_commit_log (to track progress with a high-water mark), and rag_store (to save the final indexed memories).\nExternal Services: It makes two distinct calls to the OpenAI API: one to the Chat Completions endpoint for fact distillation and another to the Embeddings endpoint for vectorization.\nLogic: The workflow is a sequential data processing pipeline that includes a crucial \"high-water mark\" system to prevent duplicate processing of messages.\n3. Step-by-Step Data Flow\nThe workflow executes in a clear, linear sequence:\nTrigger: Receive Session ID: The workflow is triggered by a POST request from the UI. The payload contains the chat_session_id and rag_session_id for the current conversation.\nGet Project ID: A Postgres node takes the chat_session_id and queries the project_contexts table to find the associated permanent project_id.\nDB: Get High-Water Mark: A Postgres node queries the memory_commit_log table to find the ID of the last message that was processed for this chat_session_id. It uses a COALESCE function to safely default to 0 if no record exists (i.e., this is the first commit for the session).\nSet: Watermark Value: A Set node takes the high_water_mark from the previous step and prepares it for the next query.\nDB: Get Conversation History: A Postgres node queries the conversation_history table, fetching all messages for the current chat_session_id whose id is greater than the highWaterMark.\nCalculate New High-Water Mark: A Code node iterates through the messages retrieved in the previous step and finds the highest message id. This value will be saved at the end of the workflow.\nIF: New Messages Found?: An If node checks if any new messages were returned. If the count is zero, the workflow stops cleanly. If new messages exist, it proceeds.\nFormat: Assemble Transcript: A Code node takes the new messages and formats them into a clean, human-readable transcript string.\nBuild: OpenAI Request Body: A Code node constructs the full JSON payload for the fact-distillation call to the OpenAI API, including a detailed system prompt and the conversation transcript.\nExecute: OpenAI API Call: An HTTPRequest node sends the payload to the OpenAI Chat Completions API (gpt-4o).\nSet: Extracted Summary: A Set node parses the AI's response and extracts the JSON string containing the distilled facts.\nChunk: Distilled Summary: A Code node parses the JSON string of facts and splits them, outputting each individual fact as a separate item to be processed in the following steps.\nAPI: Create Embeddings (HTTP) node: (Runs for each fact) An HTTPRequest node takes each fact and calls the OpenAI Embeddings API (text-embedding-3-small) to generate its vector embedding.\nMerge Embedding with Original Data: A Code node (not a Merge node) runs to assemble the final, complete payload for the database, combining the project_id, session_id, the fact text, the role (summary), and the new embedding vector.\nDB: Insert Embedding1: (Runs for each fact) A Postgres node executes the INSERT query to save the complete record for each fact into the rag_store table. It correctly links each memory to the project_id and rag_session_id that were generated in Step 2.\nDB: Update High-Water Mark: The final database operation. A Postgres node performs an UPSERT on the memory_commit_log table, saving the new_high_water_mark calculated in Step 6. This ensures the next run will only process messages created after this point.\nCount Facts & Respond to Webhook6: A final Code node counts the number of facts committed, and the Respond to Webhook node sends a detailed success message (including a \"toast\" for the UI) back to the user, completing the cycle.",
        "height": 80,
        "width": 660
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3504,
        -4080
      ],
      "id": "942315a0-c97e-438d-a441-174a283fa72b",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ ({\n  status: 'success',\n  toast: `Committed ${$('Count Facts').first().json.count ?? 0} fact(s) to memory.`,\n  status_line: `Memory updated: project_id=${$('Get Project ID').first().json.project_id}, rag_session_id=${$('Trigger: Receive Session ID').first().json.body.rag_session_id}, new_chunks=${$('Count Facts').first().json.count ?? 0}.`,\n  chunks_committed: $('Count Facts').first().json.count ?? 0,\n  project_id: $('Get Project ID').first().json.project_id,\n  rag_session_id: $('Trigger: Receive Session ID').first().json.body.rag_session_id\n}) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -1152,
        -3888
      ],
      "id": "6608ec3f-dd9c-4b01-b7e4-f11138a92e25",
      "name": "Respond to Webhook6"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        -1376,
        -3888
      ],
      "id": "86c65396-54d8-42b9-8eb8-62cdf8054339",
      "name": "Merge2"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO project_contexts (project_name, status, chat_session_id, rag_session_id)\nVALUES ($1, 'New', $2, $3)\nRETURNING xata_id AS project_id, chat_session_id AS thread_id;",
        "options": {
          "queryReplacement": "={{ [ $json.projectName, $json.chat_session_id, $json.rag_session_id ] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3072,
        -2288
      ],
      "id": "74208af0-e80f-4757-8f25-e006e964dd06",
      "name": "Postgres1",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": " SELECT\n      project_name,\n      chat_session_id,\n      rag_session_id,\n      xata_id,\n      description,\n      persona\n  FROM\n      project_contexts\n  ORDER BY\n      xata_createdat DESC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3728,
        -2400
      ],
      "id": "5a4b06e5-9edd-44d4-be27-a8032a57f03d",
      "name": "Get Project List",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// This node receives the new project name and generates unique IDs.\n\nconst body = $json.body;\n\n// 1. Validate the input from the frontend.\nif (!body.projectName || typeof body.projectName !== 'string') {\n  throw new Error(\"The 'projectName' field is missing or is not a string in the webhook body.\");\n}\n\n// 2. Generate unique IDs for the chat session and the RAG session.\nconst timestamp = Date.now();\nconst newChatId = `chat_${body.projectName.replace(/\\s+/g, '_')}_${timestamp}`;\nconst newRagId = `rag_${body.projectName.replace(/\\s+/g, '_')}_${timestamp}`;\n\n// 3. Pass all the necessary data to the next node.\nreturn [{\n  json: {\n    projectName: body.projectName,\n    chat_session_id: newChatId,\n    rag_session_id: newRagId\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3280,
        -2288
      ],
      "id": "35df3f60-d236-4c3b-a9c7-454b0eb7e3b2",
      "name": "Code2"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "fbb86eac-b086-4e9d-90a6-bce32d094885",
              "leftValue": "={{ $items.length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3504,
        -2400
      ],
      "id": "5247f661-d9ce-47db-922b-a1f2122613d7",
      "name": "If1",
      "executeOnce": false,
      "alwaysOutputData": false,
      "retryOnFail": false,
      "notesInFlow": false
    },
    {
      "parameters": {
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -3072,
        -2496
      ],
      "id": "38de6868-5c08-402a-b89c-67479647f566",
      "name": "Respond to Webhook4"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ ({ chat_session_id: $('Code2').item.json.chat_session_id, rag_session_id: $('Code2').item.json.rag_session_id }) }}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -2848,
        -2288
      ],
      "id": "c504a33a-6e63-451b-a548-1aea32809ba8",
      "name": "Respond to Webhook5"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "a61a290c-d8e5-4c04-980a-4ebb415a21e4",
        "responseMode": "responseNode",
        "options": {
          "allowedOrigins": "*"
        }
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -3952,
        -2400
      ],
      "id": "3b84151e-bfb6-41e8-a2eb-d818282e4589",
      "name": "Webhook3",
      "webhookId": "01cab1bf-43cb-40a3-a927-b5e99f875a21",
      "notesInFlow": false
    },
    {
      "parameters": {
        "content": "## System Documentation: Setup Workflow - Project Launcher\n\n\nWorkflow Name: Setup Workflow: Project Launcher for Documentation\nSource File: Setup_Workflow__Project_Launcher_for_Documentation.json\nProject Lead: Mike Holland\nSystem Architect: Gemini Pro\n1. Overall Goal\nThis workflow serves as the primary \"receptionist\" and setup engine for the Chat 8 UI. It is a dual-function workflow that automates both the creation of new, simple projects and the retrieval of the complete list of existing projects. Its core purpose is to manage the project_contexts table, ensuring each project has a unique set of identifiers before handing control back to the UI.\n2. Key Components & Architecture\nTrigger: A unique n8n Webhook (...a61a290c...) listens for POST requests from the Chat 8 UI's initial launcher screen.\nDatabase: It interacts exclusively with the project_contexts table in the Postgres database to create new project records and retrieve the full project list.\nLogic: The workflow uses an If node to act as a switch, directing the incoming request down one of two distinct paths based on an action property in the request body.\n3. Step-by-Step Data Flow\nThe workflow begins with a single entry point and immediately branches based on the user's intent.\nWebhook3: The workflow is triggered by a POST request from the UI. The payload contains a JSON body with an action key, which will be either create_project or list_projects.\nBranch A: \"List Existing Projects\"\nThis is the True path of the If1 node.\nGet Project List: A Postgres node executes a SELECT query to retrieve the project_name, chat_session_id, rag_session_id, and xata_id for all records in the project_contexts table.\nIf1: The workflow logic for this branch is slightly counter-intuitive. The If node checks if the result of the Get Project List query has more than 0 items. If True, it proceeds down this \"List Projects\" path.\nCode3: A Code node takes the list of projects from the database and transforms it to match the data contract expected by the UI, ensuring all necessary keys (project_name, session_id, project_id, rag_session_id) are present.\nRespond to Webhook4: The final Respond to Webhook node sends the formatted list of projects back to the UI, which then uses it to populate the project selection dropdown.\nBranch B: \"Create New Project\"\nThis is the False path of the If1 node.\nCode2: A Code node receives the projectName from the webhook. It generates a new, unique chat_session_id and rag_session_id based on the project name and the current timestamp.\nPostgres1: This Postgres node executes an INSERT query, using the data from the Code2 node to create a new record in the project_contexts table. It uses RETURNING xata_id to get the permanent project ID back from the database.\nRespond to Webhook5: The final Respond to Webhook node sends a success response back to the UI, providing it with the newly created chat_session_id and rag_session_id so it can initialize the new chat session.",
        "height": 80,
        "width": 752
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2832,
        -2448
      ],
      "id": "d203dccc-8110-44fc-a7a6-b55943832a41",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "jsCode": "// Get all items from the previous node's output\n  const allInputItems = $input.all();\n\n  // Use .map() to transform each item into the desired format\n  const allItems = allInputItems.map(item => {\n    return {\n      project_name: item.json.project_name,\n      session_id: item.json.chat_session_id,\n      project_id: item.json.xata_id,\n      rag_session_id: item.json.rag_session_id,\n      description: item.json.description || '',\n      persona: item.json.persona || 'dev_assistant'\n    };\n  });\n\n  // Return the final, correctly structured object\n  return {\n    json: {\n      projects: allItems\n    }\n  };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3280,
        -2496
      ],
      "id": "7601b142-3e20-4406-b503-a8f19e09a5bc",
      "name": "Code3"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "d0b91f11-487b-441f-80a3-17edd5a703db",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4032,
        -1920
      ],
      "id": "7db5772a-00a9-4135-b3d9-a33385e93eaf",
      "name": "Webhook",
      "webhookId": "0424b1cb-04c2-4c63-a8fd-b1b6aef19a8e"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO project_contexts (project_name, session_id, status, lead_contact, description, notes, rag_session_id)\nVALUES ($1, $2, $3, $4, $5, $6, $7)\nRETURNING *;",
        "options": {
          "queryReplacement": "={{ $json.sql_params }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3360,
        -1728
      ],
      "id": "ab6b4f4b-a691-42f8-ac1c-fa3540d39066",
      "name": "Postgres",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -2480,
        -1728
      ],
      "id": "1a652f3f-f1e1-459f-bd01-6e638d189723",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "{\n  \"error\": \"A project with this name already exists. Please choose a different name.\"\n}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -3584,
        -1920
      ],
      "id": "a4993520-4585-4ed0-8cb9-d5f95e48a6af",
      "name": "Respond to Webhook1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "afe88938-a540-43b8-9c58-c6f7e6903de1",
              "leftValue": "={{ $items(\"Check if Project Exists\").length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3808,
        -1824
      ],
      "id": "7af904df-f08c-456c-8d3b-a3b33bf92de6",
      "name": "If"
    },
    {
      "parameters": {
        "jsCode": "// Get the data from the previous node.\nconst data = $input.item.json;\n\n// --- FIX: Generate a NEW rag_session_id ---\n// We will create a unique ID for the RAG memory store.\nconst ragSessionId = 'rag_' + Math.random().toString(36).substring(2, 9);\n\n// Get the project name from the webhook's body property.\nconst projectName = data.body.projectName;\n\n// Generate a unique session ID for the project itself.\nconst sessionId = 'proj_' + Date.now() + '_' + Math.random().toString(36).substring(2, 9);\n\n// Set default values for the columns that actually exist.\nconst leadContact = \"\";\nconst status = \"New\";\nconst description = \"\";\nconst notes = \"\";\n\n// This is the chat session ID, which can be empty for a new project.\nconst chat_session_id = \"\"; \n\n// --- Assemble the final parameters for the SQL query ---\nconst sql_params = [\n  projectName,\n  sessionId,\n  status,\n  leadContact,\n  description,\n  notes,\n  ragSessionId // Use our newly generated ID\n];\n\n// Return the parameters for the next node.\nreturn {\n  json: {\n    sql_params: sql_params\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3584,
        -1728
      ],
      "id": "6bb0473d-b46a-4ac4-9959-7e67fabea13f",
      "name": "Code"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT project_name FROM project_contexts WHERE project_name = $1;",
        "options": {
          "queryReplacement": "=[{{ $json.body.projectName }}]"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3808,
        -2032
      ],
      "id": "15bbf5a6-a833-42f0-bb0e-3096b3649260",
      "name": "Check if Project Exists",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{\n  ({\n    \"project_id\": $('Postgres').first().json.xata_id,\n    \"session_id\": $('Generate Thread ID').first().json.new_thread_id\n  })\n}}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2704,
        -1728
      ],
      "id": "a4615b84-e16f-4522-8e3e-f679bda18e20",
      "name": "Prepare Success Response",
      "notes": "test"
    },
    {
      "parameters": {
        "jsCode": "// Generate a unique session ID for the new thread\nconst new_thread_id = `session_${Math.random().toString(36).slice(2, 11)}`;\nreturn { new_thread_id: new_thread_id };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3136,
        -1728
      ],
      "id": "47039bbe-18f2-40c7-b7af-92ba99c45131",
      "name": "Generate Thread ID"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE project_contexts SET chat_session_id = $1 WHERE xata_id = $2;",
        "options": {
          "queryReplacement": "={{ $('Generate Thread ID').first().json.new_thread_id }}\n{{ $('Postgres').first().json.xata_id }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2928,
        -1728
      ],
      "id": "f29ba1cb-4558-476a-b7b1-a03fa33813c8",
      "name": "Save Thread ID to Project",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "content": "## System Documentation: Create Project Workflow\n\n\nWorkflow Name: Create Project Workflow (as inferred from context)\nSource File: Main_Chat_Workflow_for_Documentation (1).json\nProject Lead: Mike Holland\nSystem Architect: Gemini Pro\n1. Overall Goal\nThis workflow serves as the dedicated backend process for creating a new, simple project. Its sole purpose is to receive a project name from the UI, ensure it doesn't already exist, create all the necessary records and IDs in the database, and return a success response to the UI so a new chat session can begin. It acts as a secure and robust entry point for Scenario 1.\n2. Key Components & Architecture\nTrigger: A unique n8n Webhook (...d0b91f11...) listens for POST requests from the Chat 8 UI.\nDatabase: It interacts exclusively with the project_contexts table in the Postgres database to check for duplicates and create new project records.\nLogic: The workflow follows a simple conditional path: if the project already exists, it fails gracefully; if not, it proceeds with creation.\n3. Step-by-Step Data Flow\nThe workflow executes in a clear, linear sequence:\nWebhook: The workflow is triggered when the user submits a new project name from the UI. The payload contains { \"projectName\": \"...\" }.\nCheck if Project Exists: A Postgres node immediately queries the project_contexts table to see if any record already has the provided projectName.\nIf (Project Exists?): An If node checks the result of the previous query.\nIf True (project exists): The workflow takes the True branch and immediately triggers the Respond to Webhook1 node, which sends a specific error message back to the UI, stopping the process.\nIf False (project is new): The workflow proceeds down the main False branch to create the project.\nCode (Prepare SQL Parameters): A Code node runs to prepare the data for the database INSERT command. It generates a unique rag_session_id and sessionId and assembles all the required values into an array (sql_params).\nPostgres (Create Project Record): This Postgres node executes the main INSERT query, using the sql_params from the previous step to create the new record in the project_contexts table. Crucially, it uses RETURNING * to output the full, newly created database row, including the permanent xata_id.\nGenerate Thread ID: A Code node generates a new, unique chat_session_id (formatted as session_...).\nSave Thread ID to Project: A Postgres node executes an UPDATE query. It takes the new_thread_id and the xata_id from the previous steps and updates the project record to include the new chat session ID.\nPrepare Success Response: A Set node takes the project_id (from the xata_id) and the session_id (from the new_thread_id) and formats them into a clean JSON object.\nRespond to Webhook: The final Respond to Webhook node sends this success object back to the UI, providing it with all the necessary IDs to initialize the new chat session.",
        "height": 80,
        "width": 600
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3248,
        -1840
      ],
      "id": "eb65a997-4bf3-43dd-93fb-74357d820ce0",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"model\": \"text-embedding-ada-002\", \"input\": $json.chunk_text_for_embedding } }}",
        "options": {
          "redirect": {},
          "response": {},
          "timeout": 120000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3104,
        -624
      ],
      "id": "1d9a976f-3b42-420c-aaa0-3f9882b4dcf3",
      "name": "Create Embedding1",
      "executeOnce": false,
      "credentials": {
        "openAiApi": {
          "id": "4UBMhvVGj5H8Ehzq",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Code Node: Format Vector for Postgres\n// Outputting VECTOR STRING for n8n \"Execute Query\" operation\n\nconst inputJson = $input.item.json;\nlet vectorStringForDb = '[]'; // Default\nconst embeddingVectorArray = inputJson.embedding_vector_from_api;\n\nif (embeddingVectorArray && Array.isArray(embeddingVectorArray) && embeddingVectorArray.length > 0) {\n    // Create the string '[-0.01,0.02,...]'\n    vectorStringForDb = JSON.stringify(embeddingVectorArray).trim(); \n} else {\n    console.error(\"Format Vector for PG: embedding_vector_from_api was problematic. Using default '[]'. Chunk: \" + (inputJson.original_content_for_db || \"\").substring(0,30) );\n}\n\nconst outputData = {\n  session_id_for_insert: inputJson.session_id_for_insert,\n  original_content_for_db: inputJson.original_content_for_db,\n  role_for_final_insert: inputJson.role_for_db || inputJson['role-for-db'] || 'unknown',\n  embedding_vector_string_for_db: vectorStringForDb // Outputting the string\n};\n\nif (!outputData.session_id_for_insert || !outputData.original_content_for_db || !outputData.role_for_final_insert) {\n    console.error(\"Format Vector for PG: CRITICAL - Missing required fields. Data:\", outputData);\n    return null; \n}\n\nreturn outputData;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2432,
        -704
      ],
      "id": "358076cb-c583-4810-be6c-228e989451d1",
      "name": "Format Vector for Postgres1"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO rag_store (project_id, session_id, original_content, role, embedding) VALUES ($1, $2, $3, $4, $5);",
        "options": {
          "queryBatching": "independently",
          "queryReplacement": "={{ [ $item(0).$node[\"Create Project Entry1\"].json[\"project_id\"], $item(0).$node[\"Create Project Entry1\"].json[\"rag_session_id\"], $json.original_content_for_db, $json.role_for_final_insert, $json.embedding_vector_string_for_db ] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2208,
        -704
      ],
      "id": "6082e3ed-0af4-47d5-9364-17fabc692b50",
      "name": "Insert Embedding to Xata1",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "df1df400-e07f-4834-a324-6f644c650e0d",
              "name": "session_id_for_insert",
              "value": "={{ $json.session_id_for_db }}",
              "type": "string"
            },
            {
              "id": "98488e14-449e-43ab-8f11-7bbaf90fb2db",
              "name": "original_content_for_db",
              "value": "={{ $json.chunk_text_for_embedding }}",
              "type": "string"
            },
            {
              "id": "605e03fe-51ff-434d-89a1-1b8c71126cc7",
              "name": "role-for-db",
              "value": "={{ ($json.original_role_for_db === 'model' || $json.original_role_for_db === 'assistant') ? 'assistant' : 'user' }}",
              "type": "string"
            },
            {
              "id": "21b390bb-4fa5-461d-a3e6-613ff3f5e823",
              "name": "embedding_vector_from_api",
              "value": "={{ $json.data[0].embedding }}",
              "type": "array"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2656,
        -704
      ],
      "id": "fdaf5fb6-ad20-4326-a2b1-0b536e01bc80",
      "name": "Prepare for DB1"
    },
    {
      "parameters": {
        "url": "={{ $('Webhook2').item.json.body.jsonUrl }}",
        "options": {
          "redirect": {},
          "response": {
            "response": {
              "fullResponse": false,
              "neverError": false,
              "responseFormat": "text",
              "outputPropertyName": "data"
            }
          },
          "timeout": 60000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3760,
        -704
      ],
      "id": "6fbb26cb-21b1-4efe-98af-d0b3b99cb125",
      "name": "HTTP Request GCS Fetch1"
    },
    {
      "parameters": {
        "jsCode": "// --- Intelligent Chunking Script v3 (with Debugging) ---\n\n// This line now gets the session_id from the node that created the project in the database.\nconst BATCH_SESSION_ID = $('Webhook2').item.json.body.projectName;\nconst MAX_CHUNK_SIZE_CHARS = 6000; // Safety limit (~1500 tokens)\nconst documentText = $json.data;\nconst finalItems = [];\n\n// Split the document by our manual break first.\nconst primaryChunks = documentText.split('---CHUNK_BREAK---');\n\nfor (const primaryChunk of primaryChunks) {\n    let currentChunk = primaryChunk.trim();\n    if (!currentChunk) continue;\n\n    // If a chunk is already small enough, process it.\n    if (currentChunk.length <= MAX_CHUNK_SIZE_CHARS) {\n        // --- DEBUGGING ---\n        console.log(`[OK] Chunk size: ${currentChunk.length}`);\n        finalItems.push({\n            json: {\n                chunk_text_for_embedding: currentChunk,\n                session_id_for_db: BATCH_SESSION_ID\n            }\n        });\n        continue;\n    }\n\n    // If a chunk is TOO LARGE, we must split it further.\n    // --- DEBUGGING ---\n    console.log(`[LARGE CHUNK DETECTED] Splitting chunk of size: ${currentChunk.length}`);\n    let tempChunk = \"\";\n    const sentences = currentChunk.split(/(?<=[.?!])\\s+/); // Split by sentences\n\n    for (const sentence of sentences) {\n        if ((tempChunk.length + sentence.length + 1) > MAX_CHUNK_SIZE_CHARS) {\n            // --- DEBUGGING ---\n            console.log(`[SUB-CHUNK CREATED] Size: ${tempChunk.length}`);\n            finalItems.push({\n                json: {\n                    chunk_text_for_embedding: tempChunk,\n                    session_id_for_db: BATCH_SESSION_ID\n                }\n            });\n            tempChunk = sentence;\n        } else {\n            tempChunk += (tempChunk ? \" \" : \"\") + sentence;\n        }\n    }\n    // Add the last remaining part\n    if (tempChunk) {\n        // --- DEBUGGING ---\n        console.log(`[FINAL SUB-CHUNK] Size: ${tempChunk.length}`);\n        finalItems.push({\n            json: {\n                chunk_text_for_embedding: tempChunk,\n                session_id_for_db: BATCH_SESSION_ID\n            }\n        });\n    }\n}\n\nreturn finalItems;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3536,
        -704
      ],
      "id": "02915609-6bec-4296-a5bc-80846652b764",
      "name": "Chunk Code1"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        -2880,
        -704
      ],
      "id": "6a6328b5-3096-4f39-9aca-07743ed8cd72",
      "name": "Merge Embedding with Chunk Data1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "95b4011b-5ede-4775-a952-bd6963670ce9",
              "leftValue": "={{ $json.chunk_text_for_embedding }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.filter",
      "typeVersion": 2.2,
      "position": [
        -3328,
        -704
      ],
      "id": "e0da1a8d-a447-4624-9729-19204fc4571a",
      "name": "Filter1"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH generated_ids AS (\n    SELECT\n        (EXTRACT(EPOCH FROM NOW())::BIGINT)::text AS project_id,\n        'chat_' || (EXTRACT(EPOCH FROM NOW())::BIGINT) AS chat_session_id,\n        'rag_' || REPLACE('{{$json.body.projectName}}', ' ', '_') || '_' || (EXTRACT(EPOCH FROM NOW())::BIGINT) AS rag_session_id\n),\ninserted_project AS (\n    INSERT INTO project_contexts (\n        project_name,\n        session_id,\n        chat_session_id,\n        rag_session_id,\n        status,\n        description,\n        notes,\n        lead_contact\n    )\n    SELECT\n        '{{$json.body.projectName}}',\n        g.chat_session_id,\n        g.chat_session_id,\n        g.rag_session_id,\n        'Active',\n        'Project created from Indexed URL',\n        'Source URL: {{$json.body.jsonUrl}}',\n        'Project created from URL'\n    FROM generated_ids g\n)\nSELECT project_id, chat_session_id, rag_session_id FROM generated_ids;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3984,
        -704
      ],
      "id": "2b2fe67c-bec8-4ca0-aba5-bbfcd6858ba4",
      "name": "Create Project Entry1",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{\n  ({\n    status: 'success',\n    project_id: $('Create Project Entry1').first().json.project_id,\n    session_id: $('Create Project Entry1').first().json.session_id,\n    rag_session_id: $('Create Project Entry1').first().json.rag_session_id\n  })\n}}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1984,
        -704
      ],
      "id": "e4e8ac39-80ba-41f5-b797-4e63b4504987",
      "name": "Prepare Final Response1",
      "executeOnce": true
    },
    {
      "parameters": {
        "content": "## System Documentation: RAG Indexing Workflow\n\n\n**IMPLEMENTATION NOTES - TIMEOUT FIX APPLIED**\nThis workflow has been updated with timeout configurations to resolve HTTP request failures in VM Docker environments.\n- Create Embedding1 node: 120 second timeout added\n- HTTP Request GCS Fetch1 node: 60 second timeout added\n- Workflow execution timeout: 1 hour limit\n- Error handling: saveManualExecutions enabled for debugging\n\nRECOMMENDED RETRY LOGIC (for future enhancement):\n- Add Code node after each HTTP Request for exponential backoff retry\n- Implement 3 retry attempts with 5-second delays\n- Log timeout errors for monitoring and alerting\n\n\nWorkflow Name: RAG Indexing Workflow for Documentation\nSource File: RAG_Indexing_Workflow_for_Documentation.json\nProject Lead: Mike Holland\nSystem Architect: Gemini Pro\n1. Overall Goal\nThis workflow serves as the dedicated data pipeline for bootstrapping a new project with an existing knowledge base. Its purpose is to receive a URL to a JSON file and a new project name from the UI, create the necessary project records in the database, and then systematically process the contents of the JSON file. It chunks the text, generates vector embeddings for each chunk, and saves them to the long-term memory store (rag_store), permanently associating them with the newly created project.\n2. Key Components & Architecture\nTrigger: A unique n8n Webhook (...303639ed...) listens for POST requests from the Chat 8 UI's \"Create from URL\" feature.\nDatabase: It interacts with both the project_contexts table (to create the new project) and the rag_store table (to save the indexed memories).\nExternal Services: It makes calls to Google Cloud Storage (GCS) to fetch the source JSON and to the OpenAI API to generate embeddings.\nLogic: The workflow is a sequential pipeline: create the project, fetch the data, chunk it, create embeddings, and save everything to the database.\n3. Step-by-Step Data Flow\nThe workflow executes in a clear, linear sequence:\nWebhook2: The workflow is triggered when the user submits a JSON URL and a new project name from the UI. The payload contains { \"projectName\": \"...\", \"jsonUrl\": \"...\" }.\nCreate Project Entry1: A Postgres node immediately executes a complex SQL query. This single query is responsible for:\nGenerating a new, unique project_id (numeric), chat_session_id, and rag_session_id.\nInserting a new record into the project_contexts table with these new IDs and the provided project name.\nReturning the newly generated IDs for use in subsequent steps.\nHTTP Request GCS Fetch1: An HTTPRequest node takes the jsonUrl from the initial webhook and fetches the raw text content of the JSON file from Google Cloud Storage. **TIMEOUT: 60 seconds**\nChunk Code1: A sophisticated Code node takes the raw text from the file. It intelligently splits the text into smaller, manageable chunks suitable for embedding, ensuring no chunk exceeds a maximum character limit. It outputs a list of items, each containing a text chunk.\nFilter1: A simple Filter node ensures that no empty chunks proceed, preventing wasted API calls.\nCreate Embedding1: (Runs for each chunk) An HTTPRequest node takes each text chunk and sends it to the OpenAI embeddings API (text-embedding-ada-002) to generate a vector embedding. **TIMEOUT: 120 seconds**\nMerge Embedding with Chunk Data1: A Merge node combines the original chunk data with the newly generated embedding vector from the previous step.\nPrepare for DB1: A Set node takes the merged data and restructures it, creating clean fields (session_id_for_insert, original_content_for_db, etc.) ready for the next step.\nFormat Vector for Postgres1: A Code node takes the embedding vector (which is a JavaScript array) and converts it into the specific string format (e.g., \"[0.1, 0.2, ...]\") required by the pgvector database type.\nInsert Embedding to Xata1: (Runs for each chunk) This is the final, critical database operation. A Postgres node takes the fully prepared data for each chunk and executes an INSERT query to save it to the rag_store table. It correctly links each memory to the project_id and rag_session_id that were generated in Step 2.\nPrepare Final Response1: After all chunks have been successfully inserted, a Set node runs once to format a clean success message.\nRespond to Webhook3: The final Respond to Webhook node sends the success object (containing the new project_id, session_id, and rag_session_id) back to the UI, signaling that the project has been created and indexed, and a new chat session can begin.",
        "height": 80,
        "width": 604
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2816,
        -496
      ],
      "id": "bd48c42a-0ad4-40bf-9d48-c5272c0b8b4d",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"project_id\": \"{{$item(0).$node[\"Create Project Entry1\"].json[\"project_id\"]}}\",\n  \"session_id\": \"{{$item(0).$node[\"Create Project Entry1\"].json[\"chat_session_id\"]}}\",\n  \"rag_session_id\": \"{{$item(0).$node[\"Create Project Entry1\"].json[\"rag_session_id\"]}}\"\n}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -1760,
        -704
      ],
      "id": "3cdc0226-1f73-4755-ae9c-b39b9cc93cee",
      "name": "Respond to Webhook3"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "303639ed-a3e2-4eae-b406-16e1c6200a81",
        "responseMode": "responseNode",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "http://127.0.0.1:5500"
              },
              {
                "name": "Access-Control-Allow-Methods",
                "value": "OPTIONS and POST"
              },
              {
                "name": "Access-Control-Allow-Headers",
                "value": "Content-Type"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4208,
        -704
      ],
      "id": "26d84c98-6e6d-4062-abec-460917e4505c",
      "name": "Webhook2",
      "webhookId": "ee98eeef-8c29-4f12-9e7a-91d0bd011393"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://n8n.srv997771.hstgr.cloud/webhook/ai-router",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"selected_model\": $json.model, \"messages\": $json.messages } }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1616,
        272
      ],
      "id": "e5a46bc5-9011-4e8c-b767-2269e1250d94",
      "name": "HTTP Request to AI Router"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "/*MIKE_MARKER:CODE1_ES5_V3_AI_ROUTER*/ \nvar r=$input.item&&$input.item.json?$input.item.json:{}; \nvar replyText='Error: Could not extract reply.'; \nvar toast; \n\n// Handle AI Router response format\nif(r && r.success && typeof r.content === 'string') {\n  var raw = String(r.content); \n  var cleaned = raw.replace(/[^\\x20-\\x7E\\n\\r\\t]+/g,''); \n  var maxLen = 15000; \n  if(cleaned.length > maxLen) { \n    cleaned = cleaned.substring(0, maxLen) + '... (truncated)'; \n  } \n  replyText = cleaned;\n  \n  // Handle auto-commit status messages\n  try { \n    var an = $node['Auto Commit via Webhook'].first(); \n    if(an && an.json) { \n      var statusLine = an.json.status_line; \n      var toastLine = an.json.toast; \n      if(statusLine) { \n        replyText += '\\n\\n' + statusLine; \n      } \n      if(toastLine) { \n        toast = toastLine; \n      } \n    } \n  } catch(e) {}\n} else if(r && !r.success) {\n  replyText = 'AI Router Error: ' + (r.error || 'Unknown error occurred');\n}\n\n// Get model info from Build OpenAI Payload1\nvar selected_model; \nvar usedVision = false; \ntry { \n  var pn = $node['Build OpenAI Payload1'].first(); \n  if(pn && pn.json) { \n    selected_model = pn.json.model; \n    usedVision = !!pn.json.usedVision; \n  } \n  if(!usedVision) { \n    var fci = $node['Format Current Input'].first(); \n    if(fci && fci.json && Object.prototype.toString.call(fci.json.content) === '[object Array]') { \n      var arr = fci.json.content; \n      for(var a = 0; a < arr.length; a++) { \n        var pp = arr[a]; \n        if(pp && pp.type === 'image_url') { \n          usedVision = true; \n          break; \n        } \n      } \n    } \n  } \n} catch(e) {} \n\nvar out = { reply: replyText }; \nif(selected_model) out.selected_model = selected_model; \nout.usedVision = usedVision; \nif(toast) out.toast = toast; \nif(r && r.provider) out.ai_provider = r.provider; \nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1392,
        272
      ],
      "id": "6536021f-037b-4f77-bc55-134871368e34",
      "name": "Code1"
    },
    {
      "parameters": {
        "jsCode": "// --- Prepare Consolidated RAG Context v1.0 ---\n// This script takes the single block of consolidated RAG text\n// and formats it correctly for the final prompt.\n\n// Get the combined context from the previous node's output.\nconst combinedContext = $input.item.json.combined_rag_context;\n\n// Create a single \"context\" object that the Merge node can use.\n// We will assign it the role of \"system\" to indicate it's background info.\nconst formattedRagContext = {\n  role: 'system',\n  content: `--- CONTEXT FROM KNOWLEDGE BASE ---\\n${combinedContext}`\n};\n\n// Return a single item containing this formatted object.\nreturn [{\n  json: formattedRagContext\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2272,
        192
      ],
      "id": "4860f3f7-f345-443f-b74c-7e2919239346",
      "name": "Format History for AI",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{\n  {\n    \"model\": \"text-embedding-3-small\",\n    \"input\": $('Get Session ID & Input').item.json.chatInput\n  }\n}}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3376,
        192
      ],
      "id": "593831a2-cf10-4705-828b-8ec2bf1f32ad",
      "name": "Create Query Embedding",
      "credentials": {
        "openAiApi": {
          "id": "MjVoArzZMRHgjBwn",
          "name": "OpenAi (Embeddings)"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// This node receives two inputs.\n// Input 0: From \"Create Query Embedding\"\n// Input 1: From the initial Webhook trigger\n\n// Get the embedding from the embedding creation node (input 0)\nconst embeddingData = $input.all(0)[0].json;\nconst embedding = embeddingData.data[0].embedding;\n\n// Get the data directly from the initial Webhook trigger node by its name\nconst triggerData = $('Webhook1').first().json;\n\n// Get the RAG session ID from the webhook's parsed JSON body\nconst ragSessionId = triggerData.body.rag_session_id;\n\n// Format the embedding vector into the string format for pgvector.\nconst query_embedding_for_pg = '[' + embedding.join(',') + ']';\n\n// Create the final output object.\n// It's crucial that this object has a 'json' property containing our data.\nreturn {\n  json: {\n    query_embedding_for_pg: query_embedding_for_pg,\n    current_session_id_for_search: ragSessionId\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3152,
        192
      ],
      "id": "8f57f14f-a40f-4b38-aaad-95f425996781",
      "name": "Format Data for Vector Search"
    },
    {
      "parameters": {
        "jsCode": "const body = $input.item.json.body;\n\nif (!body.chat_session_id || typeof body.chat_session_id !== 'string') {\n  throw new Error(\"The 'chat_session_id' field is missing or invalid in the webhook body.\");\n}\nif (!body.chatInput && !body.imageUrl && !body.imageData) {\n  throw new Error(\"The 'chatInput' field, 'imageUrl', or 'imageData' must be provided in the webhook body.\");\n}\n\n// Pass ALL required IDs and image info downstream. Prefer URL.\nreturn [{\n  json: {\n    chatInput: body.chatInput,\n    imageUrl: body.imageUrl || null,\n    imageData: body.imageData || null,\n    session_Id: body.chat_session_id,\n    rag_session_Id: body.rag_session_id,\n    project_Id: body.project_id\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4256,
        16
      ],
      "id": "6a537a89-b081-4518-bda0-cc8dc111d177",
      "name": "Get Session ID & Input"
    },
    {
      "parameters": {
        "content": "## System Documentation: Main Chat Workflow\n\n\nWorkflow Name: Main Chat Workflow for Documentation\nVersion: As of file provided\nProject Lead: Mike Holland\nSystem Architect: Gemini Pro\n1. Overall Goal\nThis n8n workflow serves as the central orchestration layer for the Chat 8 user interface. Its primary purpose is to receive user input, intelligently enrich it with multiple forms of context—long-term memory from a RAG store and short-term conversational history—and generate a context-aware response from a large language model. It also includes a new feature for automatically committing \"remember\" intents to memory.\n2. Key Components & Architecture\nThe system is comprised of several key components that work in concert:\nFrontend: The Chat 8 UI (Chat_8_V7.html) captures user input and displays the final response.\nBackend Orchestration: This n8n workflow manages the entire data flow and logic.\nLong-Term Memory: A Postgres database containing the rag_store for vectorized knowledge.\nShort-Term Memory: The same Postgres database, using the conversation_history table for recent conversational turns.\nThe workflow's core architecture is a multi-branch parallel processing system. After initial input, it splits into distinct paths to gather different types of context, which are then merged before the final AI call.\n3. Step-by-Step Data Flow\nThe workflow executes in several distinct phases:\nPhase 1: Ingestion and Preparation\nWebhook1: The workflow is triggered by a POST request from the UI. It is configured to handle pre-flight OPTIONS requests for CORS compatibility.\nGet Session ID & Input: A Code node parses the incoming request body. It validates that chat_session_id and chatInput are present and transforms all key IDs to a consistent camelCase format (session_Id, rag_session_Id, project_Id) for use within the workflow.\nSave User Message to History: A Postgres node immediately saves the user's message to the conversation_history table, ensuring a complete and persistent log of the interaction.\nPreserve Current Inputs: A critical Set node creates a stable, preserved copy of the key inputs (session_Id, chatInput, rag_session_Id, etc.). This node acts as a central hub, providing a reliable data source for all subsequent parallel branches.\nPhase 2: Auto-Commit Branch (Side Process)\nRunning in parallel to the main chat logic.\nConfig: Auto-Commit Enabled: A Set node acts as a feature flag, enabling the auto-commit functionality.\nIf Remember Intent: An If node checks if the user's chatInput starts with the word \"remember\".\nAuto Commit via Webhook: If the intent is to remember, an HTTPRequest node triggers the separate \"Commit to Memory\" workflow, passing the necessary IDs to save the new fact in the background.\nPhase 3: Main Logic Branching\nIf Rag is Active: This is the primary traffic controller. It checks if a rag_session_Id was provided.\nIf True: The workflow proceeds down the full RAG path to retrieve long-term memory.\nIf False: The workflow bypasses the RAG steps and proceeds directly to retrieve only the short-term conversational history.\nPhase 4: The RAG Path (Dual-Retrieval)\nThis path executes if RAG is active.\nCreate Query Embedding: An HTTPRequest node takes the user's chatInput and calls the OpenAI API to convert it into a vector embedding.\nFormat Data for Vector Search: A Code node prepares the data for the database search, formatting the embedding vector into the required string format for pgvector.\nParallel Retrieval: The workflow splits again to perform two simultaneous database lookups:\nRetrieve Committed Memory: A Postgres node searches the rag_store for memories from the live conversation.\nRetrieve RAG Chunks: A Postgres node searches the rag_store for memories from the initial bootstrapped knowledge base.\nMerge1: A Merge node combines the results from both retrieval steps into a single list.\nRAG Context consolidator: A Code node takes the merged list, removes any duplicate memories, and formats the unique results into a single, clean block of text.\nFormat History for AI: A Code node takes the consolidated text and wraps it in a standard { role: 'system', content: '...' } object, ready for the final prompt.\nPhase 5: Final Prompt Assembly & AI Call\nGet Recent history: (Runs in parallel to the RAG path) A Postgres node queries the conversation_history table for the last 6 turns of the conversation.\nFormat Recent History: A Code node formats these turns into the standard OpenAI message format.\nFormat Current Input: A Code node formats the user's current message into the standard format.\nMerge: This is the final assembly point. A Merge node combines the three streams of context:\nInput 1: The RAG context (from Format History for AI).\nInput 2: The recent conversational history (from Format Recent History).\nInput 3: The user's current message (from Format Current Input).\nBuild OpenAI Payload1: A sophisticated Code node takes the fully merged data. It intelligently selects the correct system prompt (persona), assembles the final message array in the correct order (system prompt, RAG context, history, user message), and builds the complete JSON payload for the AI.\nHTTP Request1: Sends the final payload to the OpenAI Chat Completions API.\nPhase 6: Response and Finalization\nCode1: A Code node parses the response from OpenAI, extracts the AI's reply, and performs cleaning and truncation. It also checks for any status messages from the background Auto-Commit process and appends them to the reply.\nPostgres2 (Save AI Reply): Saves the AI's generated response back to the conversation_history table.\nRespond to Webhook2: Sends the final, clean reply back to the Chat 8 UI, completing the cycle.",
        "height": 80,
        "width": 548
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3648,
        -144
      ],
      "id": "d5d01dcb-d30f-403b-a3bc-22d5ea137d62",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT role, content\n  FROM conversation_history\n  WHERE session_id = $1\n  ORDER BY created_at DESC\n  LIMIT 6\n",
        "options": {
          "queryReplacement": "={{ [$json.session_Id] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2496,
        480
      ],
      "id": "f37b38ae-1c26-41da-819f-6bc031465f34",
      "name": "Get Recent history",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Code Node: Format Recent History\n// Input: items from \"Get Recent History\" node (array of {role, content} objects, newest first)\n// Output: A single item containing a 'recent_history' array, formatted for OpenAI (oldest first)\n\nconst inputItems = $input.all(); // Get all input items (each is a row from DB)\nlet formattedHistory = [];\n\n// Check if there are any input items\nif (inputItems.length > 0) {\n    // Extract .json from each item to get the actual data rows\n    const historyRecords = inputItems.map(item => item.json); \n\n    if (historyRecords && historyRecords.length > 0) {\n      // The history from DB is newest first (ORDER BY created_at DESC), \n      // so reverse it to get oldest first for the OpenAI prompt\n      formattedHistory = historyRecords.reverse().map(record => {\n        let roleToUse = 'unknown';\n        if (typeof record.role === 'string') {\n            const dbRole = record.role.toLowerCase();\n            if (dbRole === 'user') {\n                roleToUse = 'user';\n            } else if (dbRole === 'assistant' || dbRole === 'ai' || dbRole === 'model') {\n                roleToUse = 'assistant';\n            } else {\n                console.warn(`Format Recent History: Unknown role '${dbRole}' found, mapping to 'user'. Content: ${(record.content || \"\").substring(0,50)}`);\n                roleToUse = 'user'; // Fallback for unknown roles\n            }\n        } else {\n             console.warn(`Format Recent History: Missing or invalid role for record. Defaulting to 'user'. Record:`, record);\n             roleToUse = 'user';\n        }\n        const content = (typeof record.content === 'string') ? record.content : '';\n        \n        return {\n          role: roleToUse, \n          content: content\n        };\n      });\n    }\n}\n\n// Output a single item, with the formatted history array in a property\nreturn formattedHistory.map(item => ({ json: item }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2272,
        480
      ],
      "id": "bcc99f59-e527-4dcb-8c7f-48c3064639e7",
      "name": "Format Recent History",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "conversation_history",
          "mode": "list",
          "cachedResultName": "conversation_history"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "session_id": "={{ $json.session_Id }}",
            "role": "user",
            "content": "={{ $json.chatInput }}"
          },
          "matchingColumns": [
            "id"
          ],
          "schema": [
            {
              "id": "id",
              "displayName": "id",
              "required": false,
              "defaultMatch": true,
              "display": true,
              "type": "number",
              "canBeUsedToMatch": true,
              "removed": true
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true
            },
            {
              "id": "role",
              "displayName": "role",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true
            },
            {
              "id": "content",
              "displayName": "content",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true
            },
            {
              "id": "created_at",
              "displayName": "created_at",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "dateTime",
              "canBeUsedToMatch": true,
              "removed": true
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -4032,
        16
      ],
      "id": "43716408-69ba-4f5c-9467-7416864c9911",
      "name": "Save User Message to History",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "ecc57f20-7f83-4ed7-bc40-a63bf0b318b7",
              "name": "session_Id",
              "value": "={{ $('Get Session ID & Input').item.json.session_Id }}",
              "type": "string"
            },
            {
              "id": "1454ec7a-35ff-4bf1-aaf6-0bd559c6ddca",
              "name": "chatInput",
              "value": "={{ $('Get Session ID & Input').item.json.chatInput }}",
              "type": "string"
            },
            {
              "id": "9f0a5ab1-1111-4a2e-aaaa-1234567890ab",
              "name": "imageUrl",
              "value": "={{ $('Get Session ID & Input').item.json.imageUrl }}",
              "type": "string"
            },
            {
              "id": "e45f0fda-84cf-43e7-94ff-41ed896ce7e8",
              "name": "imageData",
              "value": "={{ $('Get Session ID & Input').item.json.imageData }}",
              "type": "object"
            },
            {
              "id": "09c1b52a-2cf0-4101-8a06-8ae66e1d8ea9",
              "name": "rag_session_Id",
              "value": "={{ $('Get Session ID & Input').item.json.rag_session_Id }}",
              "type": "string"
            },
            {
              "id": "5c53893f-4d94-4559-bef2-dc3123f2ae94",
              "name": "project_Id",
              "value": "={{ $('Get Session ID & Input').item.json.project_Id }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3808,
        16
      ],
      "id": "9ee01ca6-9b8f-4142-9590-83b98063804e",
      "name": "Preserve Current Inputs"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b6a2f6aa-4b9d-4a9e-b0e3-6e1e57e7f4f1",
              "name": "autoCommitEnabled",
              "value": "true",
              "type": "boolean"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3584,
        0
      ],
      "id": "5b9ef297-682e-42fc-a1ca-ca3dfa61db2a",
      "name": "Config: Auto-Commit Enabled"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": false,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9b2a5e2c-30f2-4e2e-9e0d-7fbf5c7b8bd1",
              "leftValue": "={{ $json.chatInput }}",
              "rightValue": "^\\s*remember\\b",
              "operator": {
                "type": "string",
                "operation": "regex",
                "singleValue": true
              }
            },
            {
              "id": "f4d0a1b2-5e6f-4a7b-8c9d-1e2f3a4b5c6d",
              "leftValue": "={{ $('Config: Auto-Commit Enabled').first().json.autoCommitEnabled }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3376,
        0
      ],
      "id": "d69ae869-55f7-436c-b758-63ddca7bfd9d",
      "name": "If Remember Intent"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://n8n.srv997771.hstgr.cloud/webhook/6c1ce608-2f7a-457b-9afc-f0be5ef4bd4c",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { chat_session_id: $('Preserve Current Inputs').first().json.session_Id, rag_session_id: $('Preserve Current Inputs').first().json.rag_session_Id } }}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3152,
        0
      ],
      "id": "b5421c1a-4698-4b2e-8d91-db29489fcbbb",
      "name": "Auto Commit via Webhook"
    },
    {
      "parameters": {
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "conversation_history",
          "mode": "list",
          "cachedResultName": "conversation_history"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "session_id": "={{ $('Preserve Current Inputs').first().json.session_Id }}",
            "role": "'assistant'",
            "content": "={{ $json.reply }}"
          },
          "matchingColumns": [
            "id"
          ],
          "schema": [
            {
              "id": "id",
              "displayName": "id",
              "required": false,
              "defaultMatch": true,
              "display": true,
              "type": "number",
              "canBeUsedToMatch": true,
              "removed": true
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true
            },
            {
              "id": "role",
              "displayName": "role",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true
            },
            {
              "id": "content",
              "displayName": "content",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true
            },
            {
              "id": "created_at",
              "displayName": "created_at",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "dateTime",
              "canBeUsedToMatch": true,
              "removed": true
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1168,
        80
      ],
      "id": "faab668c-46da-40aa-916d-ea15baaece23",
      "name": "Postgres2 (Save AI Reply)",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Get all items from all inputs\nconst allItems = $input.all();\n\n// Gracefully handle cases where one or both searches return no results.\nif (allItems.length === 0) {\n  return [{ json: { combined_rag_context: \"No relevant context was found in the knowledge base.\" } }];\n}\n\n// Use a Set to automatically handle duplicates\nconst uniqueContent = new Set();\nallItems.forEach(item => {\n  if (item.json.original_content) {\n    uniqueContent.add(item.json.original_content);\n  }\n});\n\n// Join the unique snippets together\nconst combinedText = Array.from(uniqueContent).join('\\n---\\n');\n\nreturn [{\n  json: {\n    combined_rag_context: combinedText\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2496,
        192
      ],
      "id": "17acb311-6271-4b24-8ff0-669797d28741",
      "name": "RAG Context consolidator",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        -2048,
        272
      ],
      "id": "89905950-99e5-4e5c-9a19-34c1995a9381",
      "name": "Merge",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "jsCode": "/*MIKE_MARKER:FCI_v3_SIMPLIFIED*/\n// Get user message\nvar userMessage = '';\nif ($input.item && $input.item.json && $input.item.json.chatInput) {\n  userMessage = String($input.item.json.chatInput);\n}\n\n// Get image data - check current input first\nvar imageUrl = null;\nvar imageData = null;\n\nif ($input.item && $input.item.json) {\n  imageUrl = $input.item.json.imageUrl;\n  imageData = $input.item.json.imageData;\n}\n\nconsole.log('FCI v3 - userMessage:', userMessage);\nconsole.log('FCI v3 - imageUrl from input:', imageUrl);\nconsole.log('FCI v3 - imageData from input:', imageData);\n\n// Check if we have a valid image URL\nvar hasImageUrl = !!(imageUrl && typeof imageUrl === 'string' && imageUrl.length > 0 && imageUrl !== 'null');\n\n// Check if we have inline image data\nvar hasImageData = !!(imageData && imageData.dataUri);\n\nvar hasAnyImage = hasImageUrl || hasImageData;\nvar hasText = !!(userMessage && userMessage.length > 0);\n\nconsole.log('FCI v3 - hasImageUrl:', hasImageUrl);\nconsole.log('FCI v3 - hasImageData:', hasImageData);\nconsole.log('FCI v3 - hasAnyImage:', hasAnyImage);\nconsole.log('FCI v3 - hasText:', hasText);\n\nif (!hasText && !hasAnyImage) {\n  return [{ json: { role: 'user', content: '' } }];\n}\n\nvar content;\nif (hasAnyImage) {\n  var finalUrl = hasImageUrl ? imageUrl : imageData.dataUri;\n  content = [\n    { type: 'text', text: hasText ? userMessage : '' },\n    { type: 'image_url', image_url: { url: finalUrl, detail: 'auto' } }\n  ];\n  console.log('FCI v3 - Created VISION content:', JSON.stringify(content));\n} else {\n  content = userMessage;\n  console.log('FCI v3 - Created TEXT-ONLY content');\n}\n\nreturn [{ json: { role: 'user', content: content } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2272,
        -192
      ],
      "id": "2641bab7-81e8-4f02-8309-2c4f8dc9d8f4",
      "name": "Format Current Input",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "jsCode": "// Build OpenAI Payload1 - Enhanced with Model Selection\n// Input: Merged items from Format History for AI, Format Recent History, and Format Current Input\n\nvar DEFAULT_TEXT_MODEL = 'claude-4-sonnet';\nvar VISION_MODEL = 'gpt-4o';\n\n// --- Model Selection Enhancement ---\nvar frontendModel = '';\nvar modelType = 'openai';\nvar routeTo = 'openai';\n\ntry {\n  // Try the method that works in other nodes\n  var wb = null;\n  \n  try {\n    var triggerData = $('Webhook1').first().json;\n    wb = triggerData ? triggerData.body : null;\n    console.log('✅ Method SUCCESS - $(Webhook1).first().json.body:', wb ? 'found' : 'not found');\n    if (wb) {\n      console.log('🔍 Webhook body:', JSON.stringify(wb, null, 2));\n    }\n  } catch (e) {\n    console.log('❌ Method failed:', e.message);\n  }\n  \n  console.log('🔍 selected_model value:', wb ? wb.selected_model : 'no webhook data');\n  console.log('🔍 selected_model type:', wb && wb.selected_model ? typeof wb.selected_model : 'undefined');\n  \n  if (wb && wb.selected_model && typeof wb.selected_model === 'string' && wb.selected_model.trim()) {\n    frontendModel = wb.selected_model.trim();\n    console.log('✅ Frontend model set to:', frontendModel);\n    \n    // Determine model type and routing\n    if (frontendModel.toLowerCase().includes('claude')) {\n      modelType = 'claude';\n      routeTo = 'claude';\n      console.log('🔀 Routing to Claude');\n    } else if (frontendModel.toLowerCase().includes('gpt')) {\n      modelType = 'openai';\n      routeTo = 'openai';\n      console.log('🔀 Routing to OpenAI');\n    }\n  } else {\n    console.log('❌ selected_model condition failed:', {\n      hasWb: !!wb,\n      hasSelectedModel: wb ? !!wb.selected_model : false,\n      selectedModelValue: wb ? wb.selected_model : 'no wb',\n      selectedModelType: wb && wb.selected_model ? typeof wb.selected_model : 'no type',\n      trimTest: wb && wb.selected_model ? wb.selected_model.trim() : 'no trim'\n    });\n  }\n  \n  // Legacy vision model override\n  if (wb && wb.vision_model) {\n    VISION_MODEL = wb.vision_model.trim();\n  }\n} catch (e) {\n  console.log('❌ Error accessing webhook:', e);\n}\n\nfunction pickSystemPrompt() {\n   var personas = {\n      bob: 'You are Bob, a helpful and knowledgeable AI assistant.',\n      coach: 'You are a supportive coach.',\n      pm: 'You are a pragmatic project manager.'\n    };\n    try {\n      var body = $('Webhook1').first().json.body || {};  // ✅ FIXED: Changed $node to $()\n      console.log('🎭 pickSystemPrompt - Webhook body received:', JSON.stringify(body, null, 2));\n\n      var direct = (typeof body.system_prompt_content === 'string') ? body.system_prompt_content.trim() : '';\n      console.log('🎭 pickSystemPrompt - system_prompt_content:', direct ? 'FOUND (' + direct.substring(0, 50) + '...)' : 'NOT FOUND');\n\n      if (direct) {\n        console.log('✅ Using direct system_prompt_content from frontend');\n        return direct;\n      }\n\n      var key = (body.persona_key || '').toString().toLowerCase();\n      console.log('🎭 pickSystemPrompt - persona_key:', key || 'NONE');\n\n      if (personas[key]) {\n        console.log('✅ Using hardcoded persona:', key);\n        return personas[key];\n      }\n\n      console.log('⚠️ No persona found, falling back to Bob');\n    } catch (e) {\n      console.log('❌ pickSystemPrompt ERROR:', e.message);\n    }\n    return personas.bob;\n}\n\n// Get all merged items\nvar items = $input.all().map(function (it) { return it.json; });\n\n// Extract RAG context from system role messages\nvar ragContext = items\n  .filter(function (m) { return m.role === 'system'; })\n  .map(function (m) { return m.content; })\n  .join('\\n\\n');\n\n// Build final system message with RAG context\nvar finalSystem = pickSystemPrompt();\nif (ragContext) {\n  finalSystem += '\\n\\n--- Relevant Knowledge Base Context ---\\n' + ragContext;\n}\nfinalSystem += '\\n\\nFormatting rules: Use Markdown. Prefer short sections with headings when helpful. Use bullet lists for lists. Bold short labels. Use tables only when clearly beneficial. Keep responses concise and scannable.';\n\n// Start with system message\nvar messages = [{ role: 'system', content: finalSystem }];\n\n// Add all non-system messages (history and current input)\nvar nonSystem = items.filter(function (m) { return m.role !== 'system'; });\nmessages = messages.concat(nonSystem);\n\n// Check for vision usage in any message content\nvar usedVision = false;\nfor (var i = 0; i < nonSystem.length && !usedVision; i++) {\n  var c = nonSystem[i] && nonSystem[i].content;\n  if (Object.prototype.toString.call(c) === '[object Array]') {\n    for (var j = 0; j < c.length; j++) {\n      if (c[j] && c[j].type === 'image_url') {\n        usedVision = true;\n        break;\n      }\n    }\n  }\n}\n\n// Enhanced model selection logic\nvar model;\nconsole.log('🎯 Final Model Selection Debug:');\nconsole.log('- frontendModel:', frontendModel);\nconsole.log('- usedVision:', usedVision);\nconsole.log('- modelType:', modelType);\nconsole.log('- DEFAULT_TEXT_MODEL:', DEFAULT_TEXT_MODEL);\nconsole.log('- VISION_MODEL:', VISION_MODEL);\n\nif (frontendModel) {\n  model = frontendModel;\n  console.log('✅ Using frontendModel:', model);\n  // For vision with OpenAI, override with vision model\n  if (usedVision && modelType === 'openai') {\n    model = VISION_MODEL;\n    console.log('🖼️ Vision override to:', model);\n  }\n  // Claude handles vision natively, so keep the selected model\n} else {\n  // Fallback to original logic\n  model = usedVision ? VISION_MODEL : DEFAULT_TEXT_MODEL;\n  console.log('⚠️ Using fallback model:', model, '(usedVision:', usedVision, ')');\n}\n\nconsole.log('🎯 Final model decision:', model);\n\nreturn [{ \n  json: { \n    model: model, \n    messages: messages, \n    usedVision: usedVision,\n    frontendModel: frontendModel,\n    modelType: modelType,\n    routeTo: routeTo\n  } \n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1824,
        272
      ],
      "id": "1593b886-070e-4485-bc24-06153c73a558",
      "name": "Build OpenAI Payload1"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -4256,
        -192
      ],
      "id": "2e5c6ad1-9241-497d-ba8c-592299ad45ca",
      "name": "Pre-flight Request"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "4b3cfa86-fdf5-4632-bbd3-84bb73ffb9bf",
              "leftValue": "={{ $json.rag_session_Id }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3584,
        464
      ],
      "id": "e9474f0d-6dd5-4819-b567-aa9bb0d92a47",
      "name": "If Rag is Active"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT\n  original_content,\n  role,\n  embedding <=> $3::vector AS distance\nFROM\n  rag_store\nWHERE\n  project_id = $1 AND session_id = $2\nORDER BY\n  distance ASC\nLIMIT 3",
        "options": {
          "queryReplacement": "=[\n  {{ $('Preserve Current Inputs').first().json.project_Id }},\n  {{ $('Format Data for Vector Search').first().json.current_session_id_for_search }},\n  {{ $('Format Data for Vector Search').first().json.query_embedding_for_pg }}\n]"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2928,
        96
      ],
      "id": "382ad05b-c9e8-4d3a-a998-7ab0b6456f95",
      "name": "Retrieve Committed Memory",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT\n  original_content,\n  role,\n  embedding <=> $3::vector AS distance\nFROM\n  rag_store\nWHERE\n  project_id = $1 AND session_id = $2\nORDER BY\n  distance ASC\nLIMIT 3",
        "options": {
          "queryReplacement": "=[\n  {{ $('Preserve Current Inputs').first().json.project_Id }},\n  {{ $('Format Data for Vector Search').first().json.current_session_id_for_search }},\n  {{ $('Format Data for Vector Search').first().json.query_embedding_for_pg }}\n]"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2928,
        288
      ],
      "id": "c883f932-9971-46a4-a773-37b31e4ad4fa",
      "name": "Retrieve RAG Chunks",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        -2704,
        192
      ],
      "id": "25448bf2-2a85-4004-a869-474df63fe0bc",
      "name": "Merge1",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -1168,
        272
      ],
      "id": "66d73341-cf17-4001-9295-b840e261dffd",
      "name": "Respond to Webhook2"
    },
    {
      "parameters": {
        "multipleMethods": true,
        "path": "3c92075f-a856-439a-b70d-73f3c847f8fa",
        "responseMode": "responseNode",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Methods",
                "value": "GET, POST, OPTIONS"
              },
              {
                "name": "Access-Control-Allow-Headers",
                "value": "Content-Type, Authorization"
              },
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4480,
        -112
      ],
      "id": "e5d855d6-3b32-4c1f-be0a-c83a2647c905",
      "name": "Webhook1",
      "webhookId": "394edd83-5a13-401a-8799-fe0cc858cfc8",
      "options": {
        "allowedOrigins": "*",
        "responseHeaders": {
          "entries": [
            {
              "name": "Access-Control-Allow-Methods",
              "value": "GET, POST, OPTIONS"
            },
            {
              "name": "Access-Control-Allow-Headers",
              "value": "Content-Type, Authorization"
            },
            {
              "name": "Access-Control-Allow-Origin",
              "value": "*"
            }
          ]
        }
      },
      "notes": "update 2"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ai-router",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -3792,
        -1184
      ],
      "id": "a5771ebc-574d-4f56-9a53-f7567a8e57a3",
      "name": "AI Router Webhook",
      "webhookId": "45a9753f-178c-4e21-ac4d-9e3e4da73c48"
    },
    {
      "parameters": {
        "jsCode": "// AI Router Input Processor\nvar body = $json.body || $json || {};\nvar selectedModel = body.selected_model || body.model || 'gpt-4o';\nvar messages = body.messages || [];\n\n// Determine if this is a Claude model - be very specific\nvar modelLower = selectedModel.toLowerCase();\nvar isClaudeModel = modelLower.includes('claude-') || modelLower.startsWith('claude');\n\n// For GPT models, ensure they are NOT Claude\nif (modelLower.includes('gpt') || modelLower.includes('openai')) {\n  isClaudeModel = false;\n}\n\n// Debug logging\nconsole.log('=== AI Router Debug ===');\nconsole.log('Selected Model:', selectedModel);\nconsole.log('Model Lower:', modelLower);\nconsole.log('Is Claude Model:', isClaudeModel);\nconsole.log('Expected Path:', isClaudeModel ? 'Claude' : 'OpenAI');\n\nreturn {\n  selectedModel: selectedModel,\n  messages: messages,\n  isClaudeModel: isClaudeModel,\n  originalPayload: body,\n  debug: {\n    selectedModel: selectedModel,\n    isClaudeModel: isClaudeModel,\n    modelLower: modelLower,\n    expectedPath: isClaudeModel ? 'Claude' : 'OpenAI'\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3584,
        -1184
      ],
      "id": "7e037ef8-5d10-4e6c-88a9-4f3a5d2bee1e",
      "name": "Input Processor"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": false,
            "leftValue": "",
            "typeValidation": "loose"
          },
          "conditions": [
            {
              "id": "claude-check",
              "leftValue": "={{ $json.selectedModel }}",
              "rightValue": "claude",
              "operator": {
                "type": "string",
                "operation": "contains",
                "caseSensitive": false
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3392,
        -1184
      ],
      "id": "55cab461-bdc7-4d43-a460-558877f0d096",
      "name": "Provider Check"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"model\": $json.selectedModel, \"messages\": $json.messages, \"max_tokens\": 4000 } }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3184,
        -1296
      ],
      "id": "3357184f-7a61-4e95-909a-4fff1c51013a",
      "name": "OpenAI Request",
      "credentials": {
        "openAiApi": {
          "id": "4UBMhvVGj5H8Ehzq",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Claude Preprocessor v6.2 - Handles both HTTPS URLs and data URLs\nconsole.log('=== CLAUDE PREPROCESSOR v6.2 START ===');\nconsole.log('Input $json:', JSON.stringify($json, null, 2));\n\nvar originalPayload = $json.originalPayload || {};\nvar messages = $json.messages || [];\nvar selectedModel = $json.selectedModel;\n\nconsole.log('Extracted values:', {\n  originalPayload: originalPayload,\n  messagesCount: messages.length,\n  selectedModel: selectedModel\n});\n\n// Map frontend model names to ACTUAL Claude API model identifiers (2025)\nvar claudeModelMap = {\n  'claude-4-sonnet': 'claude-sonnet-4-20250514',\n  'claude-4.1-opus': 'claude-opus-4-1-20250805',\n  'claude-4-opus': 'claude-opus-4-20250514',\n  'claude-3.7-sonnet': 'claude-3-7-sonnet-20250219',\n  'claude-3-7-sonnet': 'claude-3-7-sonnet-20250219',\n  'claude-3.5-haiku': 'claude-3-5-haiku-20241022',\n  'claude-3-haiku': 'claude-3-haiku-20240307',\n  'claude-haiku-3.5': 'claude-3-5-haiku-20241022'\n};\n\n// Get the correct Claude API model identifier\nvar claudeApiModel = claudeModelMap[selectedModel] || 'claude-sonnet-4-20250514';\n\nconsole.log('=== Model Mapping ===');\nconsole.log('Frontend Model:', selectedModel);\nconsole.log('Mapped Claude Model:', claudeApiModel);\nconsole.log('Message count:', messages.length);\n\n// Convert OpenAI format to Claude format\nvar systemMessage = '';\nvar filteredMessages = [];\n\nconsole.log('=== Starting Message Processing ===');\nconsole.log('Raw messages:', JSON.stringify(messages, null, 2));\n\nfor (var i = 0; i < messages.length; i++) {\n  console.log('=== Processing Message', i, '===');\n  console.log('Message role:', messages[i].role);\n  console.log('Message content type:', typeof messages[i].content);\n  console.log('Is content array:', Array.isArray(messages[i].content));\n  \n  if (messages[i].role === 'system') {\n    systemMessage = messages[i].content || '';\n    console.log('Found system message, length:', systemMessage.length);\n  } else {\n    var messageContent = messages[i].content;\n    console.log('Processing non-system message with content:', typeof messageContent);\n    \n    // Handle image content conversion from OpenAI to Anthropic format\n    if (Array.isArray(messageContent)) {\n      console.log('Found multipart content with', messageContent.length, 'items');\n      var convertedContent = [];\n      for (var j = 0; j < messageContent.length; j++) {\n        var contentItem = messageContent[j];\n        console.log('Processing content item', j, 'type:', contentItem.type);\n        \n        if (contentItem.type === 'image_url') {\n          console.log('=== IMAGE PROCESSING START ===');\n          console.log('Image URL structure:', JSON.stringify(contentItem, null, 2));\n          \n          // Extract image URL from OpenAI format\n          var imageUrl = contentItem.image_url.url;\n          var base64Data = '';\n          var mediaType = 'image/jpeg'; // default\n          \n          console.log('Image URL type:', imageUrl.startsWith('data:') ? 'data URL' : 'HTTPS URL');\n          \n          // Handle different image URL formats\n          if (imageUrl.startsWith('data:')) {\n            // Extract base64 data from data URI\n            console.log('Processing data URL...');\n            var base64Start = imageUrl.indexOf(',') + 1;\n            base64Data = imageUrl.substring(base64Start);\n            \n            // Extract media type\n            var matches = imageUrl.match(/^data:([^;]+);base64,(.+)$/);\n            if (matches && matches.length === 3) {\n              mediaType = matches[1];\n              base64Data = matches[2];\n              console.log('Successfully extracted base64 data:', {\n                mediaType: mediaType,\n                dataLength: base64Data.length\n              });\n            } else {\n              // Fallback parsing for malformed data URLs\n              console.log('Using fallback parsing for data URL');\n              if (imageUrl.includes('image/png')) mediaType = 'image/png';\n              else if (imageUrl.includes('image/jpeg') || imageUrl.includes('image/jpg')) mediaType = 'image/jpeg';\n              else if (imageUrl.includes('image/webp')) mediaType = 'image/webp';\n              else if (imageUrl.includes('image/gif')) mediaType = 'image/gif';\n              console.log('Fallback extraction successful:', {\n                mediaType: mediaType,\n                dataLength: base64Data.length\n              });\n            }\n            \n            // Clean and validate base64 data\n            if (!base64Data || base64Data.length === 0) {\n              console.error('=== ERROR: Empty base64 data ===');\n              continue;\n            }\n            \n            // Clean base64 data\n            base64Data = base64Data.replace(/\\s+/g, '').replace(/\\n/g, '').replace(/\\r/g, '');\n            \n            // Ensure it's valid base64 characters only\n            base64Data = base64Data.replace(/[^A-Za-z0-9+/=]/g, '');\n            \n            // Pad if necessary\n            if (base64Data.length % 4 !== 0) {\n              var padding = 4 - (base64Data.length % 4);\n              if (padding < 4) {\n                base64Data += '='.repeat(padding);\n              }\n            }\n            \n            // Final validation\n            try {\n              var testData = base64Data.substring(0, Math.min(100, base64Data.length));\n              if (testData.length >= 4) {\n                atob(testData.substring(0, 4));\n              }\n              console.log('Base64 validation passed');\n            } catch (e) {\n              console.error('=== ERROR: Invalid base64 data ===');\n              console.error('Error:', e.message);\n              continue;\n            }\n            \n            // Ensure media type is supported\n            var supportedTypes = ['image/jpeg', 'image/png', 'image/webp', 'image/gif'];\n            if (!supportedTypes.includes(mediaType)) {\n              console.log('Unsupported media type, defaulting to image/jpeg:', mediaType);\n              mediaType = 'image/jpeg';\n            }\n            \n            console.log('=== IMAGE CONVERSION SUCCESS ===');\n            console.log('Final image data:', {\n              mediaType: mediaType,\n              base64Length: base64Data.length,\n              base64Preview: base64Data.substring(0, 20) + '...'\n            });\n            \n            // Create Claude format for base64\n            convertedContent.push({\n              type: 'image',\n              source: {\n                type: 'base64',\n                media_type: mediaType,\n                data: base64Data\n              }\n            });\n            \n          } else if (imageUrl.startsWith('http')) {\n            // For HTTPS URLs, pass directly to Claude (Claude supports URL format)\n            console.log('Processing HTTPS URL:', imageUrl.substring(0, 100) + '...');\n            \n            // Determine media type from URL extension\n            if (imageUrl.toLowerCase().includes('.png')) {\n              mediaType = 'image/png';\n            } else if (imageUrl.toLowerCase().includes('.jpg') || imageUrl.toLowerCase().includes('.jpeg')) {\n              mediaType = 'image/jpeg';\n            } else if (imageUrl.toLowerCase().includes('.webp')) {\n              mediaType = 'image/webp';\n            } else if (imageUrl.toLowerCase().includes('.gif')) {\n              mediaType = 'image/gif';\n            } else {\n              mediaType = 'image/jpeg'; // default fallback\n            }\n            \n            console.log('HTTPS URL will be passed directly to Claude:', {\n              url: imageUrl.substring(0, 50) + '...',\n              mediaType: mediaType\n            });\n            \n            // Create Claude format for URL (not base64)\n            convertedContent.push({\n              type: 'image',\n              source: {\n                type: 'url',\n                url: imageUrl\n              }\n            });\n            \n            console.log('=== IMAGE URL CONVERSION SUCCESS ===');\n            \n          } else {\n            console.error('=== UNSUPPORTED IMAGE FORMAT ===');\n            console.error('Only data: and https: URLs are supported. Received:', imageUrl.substring(0, 100));\n            continue; // Skip this image\n          }\n          \n        } else {\n          // Keep text content as-is\n          console.log('Keeping text content item:', contentItem.type || 'text');\n          convertedContent.push(contentItem);\n        }\n      }\n      messageContent = convertedContent;\n      console.log('Converted content array length:', convertedContent.length);\n    } else {\n      console.log('Content is not array, keeping as text:', typeof messageContent);\n    }\n    \n    filteredMessages.push({\n      role: messages[i].role,\n      content: messageContent\n    });\n    \n    console.log('Processed message ' + i + ':', {\n      role: messages[i].role,\n      contentType: Array.isArray(messageContent) ? 'multipart' : 'text',\n      contentLength: Array.isArray(messageContent) ? messageContent.length : messageContent.length\n    });\n  }\n}\n\n// Build Claude payload\nvar claudePayload = {\n  model: claudeApiModel,\n  max_tokens: originalPayload.max_tokens || 4000,\n  messages: filteredMessages\n};\n\nif (systemMessage) {\n  claudePayload.system = systemMessage;\n}\n\n// Final validation\nconsole.log('=== FINAL PAYLOAD VALIDATION ===');\nconsole.log('Model:', claudePayload.model);\nconsole.log('Messages count:', claudePayload.messages ? claudePayload.messages.length : 'undefined');\nconsole.log('System message present:', !!claudePayload.system);\n\nif (!claudePayload.model || !claudePayload.messages || claudePayload.messages.length === 0) {\n  console.error('=== CRITICAL ERROR: Invalid Claude payload ===');\n  console.error('Full payload:', JSON.stringify(claudePayload, null, 2));\n  throw new Error('Invalid payload: missing model or messages');\n}\n\n// Validate image content structure\nfor (var k = 0; k < claudePayload.messages.length; k++) {\n  var msg = claudePayload.messages[k];\n  if (Array.isArray(msg.content)) {\n    for (var l = 0; l < msg.content.length; l++) {\n      var content = msg.content[l];\n      if (content.type === 'image' && content.source) {\n        if (content.source.type === 'base64' && (!content.source.data || content.source.data.length === 0)) {\n          console.error('Empty image data in message', k, 'content', l);\n          throw new Error('Invalid image: empty base64 data');\n        }\n        if (content.source.type === 'url' && (!content.source.url || content.source.url.length === 0)) {\n          console.error('Empty image URL in message', k, 'content', l);\n          throw new Error('Invalid image: empty URL');\n        }\n        if (!content.source.media_type && content.source.type === 'base64') {\n          content.source.media_type = 'image/jpeg';\n        }\n        console.log('Image validation passed for message', k, 'content', l, 'type:', content.source.type);\n      }\n    }\n  }\n}\n\nconsole.log('=== PREPROCESSOR v6.2 SUCCESS ===');\nconsole.log('Final Claude Payload:', JSON.stringify(claudePayload, null, 2));\n\nreturn {\n  claudePayload: claudePayload,\n  selectedModel: selectedModel,\n  claudeApiModel: claudeApiModel\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3184,
        -1088
      ],
      "id": "cad7cac9-02dc-4f44-89a3-be4430122776",
      "name": "Claude Preprocessor"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.claudePayload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2976,
        -1088
      ],
      "id": "d2237489-a941-4b65-820f-e6be675f09f6",
      "name": "Claude Request",
      "credentials": {
        "anthropicApi": {
          "id": "4t4ANeac7zJTypWv",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Normalize OpenAI Response\nvar response = $json;\nvar selectedModel = 'unknown';\n\n// Try to get the selected model from the input processor\ntry {\n  var inputProcessorData = $('Input Processor').first();\n  if (inputProcessorData && inputProcessorData.json) {\n    selectedModel = inputProcessorData.json.selectedModel || 'unknown';\n  }\n} catch(e) {\n  // Fallback: try to get from response or use default\n  selectedModel = response.model || 'gpt-4o';\n}\n\nvar normalizedResponse = {};\n\nif (response.choices && response.choices[0] && response.choices[0].message) {\n  normalizedResponse = {\n    success: true,\n    provider: 'openai',\n    model: selectedModel,\n    content: response.choices[0].message.content,\n    usage: response.usage || {}\n  };\n} else {\n  normalizedResponse = {\n    success: false,\n    provider: 'openai',\n    model: selectedModel,\n    error: 'Invalid OpenAI response format',\n    raw_response: response\n  };\n}\n\nreturn normalizedResponse;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2976,
        -1296
      ],
      "id": "8ee99651-d6eb-4702-a5c4-a9897b32a889",
      "name": "OpenAI Normalizer"
    },
    {
      "parameters": {
        "jsCode": "// Normalize Claude Response\nvar response = $json;\nvar selectedModel = 'unknown';\nvar displayModel = 'claude-sonnet-4';\n\nconsole.log('=== Claude Normalizer Debug ===');\nconsole.log('Received response:', JSON.stringify(response, null, 2));\n\n// Try to get the selected model from the claude preprocessor\ntry {\n  var claudeData = $('Claude Preprocessor').first();\n  if (claudeData && claudeData.json) {\n    selectedModel = claudeData.json.selectedModel || 'unknown';\n    var claudeApiModel = claudeData.json.claudeApiModel;\n    \n    // Use a clean display name based on the API model\n    if (claudeApiModel && claudeApiModel.includes('claude-sonnet-4')) {\n      displayModel = 'claude-4-sonnet';\n    } else if (claudeApiModel && claudeApiModel.includes('claude-opus-4-1')) {\n      displayModel = 'claude-4.1-opus';\n    } else if (claudeApiModel && claudeApiModel.includes('claude-opus-4')) {\n      displayModel = 'claude-4-opus';\n    } else if (claudeApiModel && claudeApiModel.includes('claude-3-7-sonnet')) {\n      displayModel = 'claude-3.7-sonnet';\n    } else if (claudeApiModel && claudeApiModel.includes('claude-3-5-haiku')) {\n      displayModel = 'claude-3.5-haiku';\n    } else if (claudeApiModel && claudeApiModel.includes('claude-3-haiku')) {\n      displayModel = 'claude-3-haiku';\n    } else {\n      displayModel = selectedModel; // fallback to frontend name\n    }\n  }\n} catch(e) {\n  console.log('Error getting claude data:', e.message);\n  selectedModel = 'claude-4-sonnet';\n  displayModel = 'claude-4-sonnet';\n}\n\nconsole.log('Frontend Model:', selectedModel);\nconsole.log('Display Model:', displayModel);\n\nvar normalizedResponse = {};\n\nif (response.content && response.content[0] && response.content[0].text) {\n  normalizedResponse = {\n    success: true,\n    provider: 'claude',\n    model: displayModel,\n    content: response.content[0].text,\n    usage: response.usage || {}\n  };\n  console.log('Successfully normalized Claude response');\n} else {\n  console.log('Failed to normalize Claude response - invalid format');\n  normalizedResponse = {\n    success: false,\n    provider: 'claude',\n    model: displayModel,\n    error: 'Invalid Claude response format',\n    raw_response: response\n  };\n}\n\nconsole.log('Final normalized response:', JSON.stringify(normalizedResponse, null, 2));\nreturn normalizedResponse;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2784,
        -1088
      ],
      "id": "03da5066-95de-4179-94c7-919565d5c73c",
      "name": "Claude Normalizer"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        -2576,
        -1184
      ],
      "id": "dd92c0e9-aaac-4009-85a8-d3e358001eb6",
      "name": "Response"
    },
    {
      "parameters": {
        "content": "## AI Router",
        "height": 80,
        "width": 160
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -3472,
        -1312
      ],
      "typeVersion": 1,
      "id": "2f7404f6-18c4-45f0-9f72-b212568878dd",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "load-conversation-history",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -3696,
        -2896
      ],
      "id": "de0de803-6a81-45be-8e6c-f29f2aa1d64f",
      "name": "Webhook: Load History Trigger",
      "webhookId": "load-conversation-history"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT role, content, created_at\nFROM conversation_history\nWHERE session_id = $1\nORDER BY created_at ASC\nLIMIT $2;",
        "options": {
          "queryReplacement": "={{ [$json.body.chat_session_id, $json.body.max_context || 100] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3472,
        -2896
      ],
      "id": "5e9cb1ab-e15f-4bfc-8bf5-43fdd6cc38a3",
      "name": "Postgres: Get Conversation History",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Normalize Postgres results to always return an array\n  const items = $input.all();\n\n  // Extract messages from Postgres results, filtering out empty items\n  const messages = items\n    .filter(item => item.json && item.json.role && item.json.content)\n    .map(item => ({\n      role: item.json.role,\n      content: item.json.content,\n      created_at: item.json.created_at\n    }));\n\n  // Get session_id from webhook\n  const sessionId = $('Webhook: Load History Trigger').first().json.body.chat_session_id;\n\n  // Return normalized response\n  return [\n    {\n      json: {\n        success: true,\n        messages: messages,\n        count: messages.length,\n        session_id: sessionId\n      }\n    }\n  ];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3248,
        -2896
      ],
      "id": "8f033f61-fe60-40d9-bf29-3a5da3bd594e",
      "name": "Code: Normalize Response"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              },
              {
                "name": "Access-Control-Allow-Methods",
                "value": "POST, GET, OPTIONS"
              },
              {
                "name": "Access-Control-Allow-Headers",
                "value": "Content-Type"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        -3024,
        -2896
      ],
      "id": "3960169e-5d8f-4bfb-a99a-209b11cfc2a8",
      "name": "Respond: Return History"
    },
    {
      "parameters": {
        "content": "## Load Conversation History\n\n# System Documentation: Load Conversation History Workflow\n\n**Workflow Name:** Load Conversation History\n**Version:** v1.1.0\n**Created:** October 23, 2025\n**Project Lead:** Mike Holland\n**System Architect:** Claude Code AI Assistant\n\n---\n\n## 1. Overall Goal\n\nThis n8n workflow provides a dedicated API endpoint for loading complete conversation history from the database. Its primary purpose is to enable **platform-agnostic chat persistence** by allowing the frontend to retrieve full conversation context from any device, regardless of localStorage availability.\n\nUnlike the Master Chat Workflow's \"Get Recent history\" node (which loads only the last 6 messages for immediate context), this workflow is designed to load entire conversations for UI display and cross-device synchronization.\n\n---\n\n## 2. Key Features\n\n### Platform-Agnostic Architecture\n- **Database as Source of Truth**: Conversations persist in PostgreSQL, not browser localStorage\n- **Cross-Device Access**: Same conversation accessible from any computer/browser\n- **Configurable Context Window**: Frontend controls how many messages to load (20-100+)\n- **Graceful Fallback**: Frontend can fall back to localStorage if endpoint unavailable\n\n### Robust Response Handling\n- **Normalization Layer**: Always returns consistent array structure\n- **Empty Session Support**: Returns `[]` instead of undefined/null for new sessions\n- **CORS Enabled**: Works with GitHub Pages and other cross-domain deployments\n- **Error Prevention**: Code node prevents JSON parsing errors in frontend\n\n---\n\n## 3. Architecture Overview\n\nThis is a **4-node linear workflow**:\n\n```\nWebhook Trigger → Postgres Query → Code Normalization → Response\n```\n\nEach node has a specific, focused responsibility:\n\n1. **Webhook**: Receive POST request with session_id\n2. **Postgres**: Query conversation_history table\n3. **Code**: Normalize results to consistent array format\n4. **Response**: Return JSON with CORS headers\n\n---\n\n## 4. Step-by-Step Data Flow\n\n### Phase 1: Webhook Trigger\n**Node:** \"Webhook: Load History Trigger\"\n**Type:** Webhook (POST)\n**Path:** `/webhook/load-conversation-history`\n\n**Input from Frontend:**\n```json\n{\n  \"chat_session_id\": \"session_vqf27hq8x\",\n  \"max_context\": 100\n}\n```\n\n**Key Points:**\n- Accepts POST requests only\n- `chat_session_id` (required): The session to load\n- `max_context` (optional): Number of messages to retrieve (default: 100)\n- Frontend sends `chat_session_id` per Master Data Contract\n\n---\n\n### Phase 2: Database Query\n**Node:** \"Postgres: Get Conversation History\"\n**Type:** Postgres (Execute Query)\n**Credential:** \"Postgres account\" (shared with Master Workflow)\n\n**SQL Query:**\n```sql\nSELECT role, content, created_at\nFROM conversation_history\nWHERE session_id = $1\nORDER BY created_at ASC\nLIMIT $2;\n```\n\n**Query Parameters:**\n```javascript\n={{ [$json.body.chat_session_id, $json.body.max_context || 100] }}\n```\n\n**Field Mapping:**\n- Frontend sends: `chat_session_id`\n- Database uses: `session_id`\n- Parameter mapping handles the translation\n\n**Data Retrieved:**\n- `role`: \"user\" or \"assistant\"\n- `content`: The actual message text\n- `created_at`: Timestamp for chronological ordering\n\n**Sort Order:** `ASC` (oldest first) - Frontend can reverse if needed for display\n\n**Important:** `alwaysOutputData: true` ensures node executes even with 0 results\n\n---\n\n### Phase 3: Response Normalization\n**Node:** \"Code: Normalize Response\"\n**Type:** Code (JavaScript)\n**Purpose:** Prevent undefined/null responses that break frontend JSON parsing\n\n**JavaScript Logic:**\n```javascript\n// Normalize Postgres results to always return an array\nconst items = $input.all();\n\n// Extract messages from Postgres results\nconst messages = items.map(item => ({\n  role: item.json.role,\n  content: item.json.content,\n  created_at: item.json.created_at\n}));\n\n// Get session_id from webhook\nconst sessionId = $('Webhook: Load History Trigger').first().json.body.chat_session_id;\n\n// Return normalized response\nreturn [\n  {\n    json: {\n      success: true,\n      messages: messages,\n      count: messages.length,\n      session_id: sessionId\n    }\n  }\n];\n```\n\n**Why This Matters:**\n- **Problem:** Direct Postgres output can be `undefined` or have inconsistent structure\n- **Solution:** Always returns object with `messages` array (even if empty: `[]`)\n- **Benefit:** Frontend can safely do `result.messages.forEach()` without null checks\n\n**Empty Session Example:**\n```json\n{\n  \"success\": true,\n  \"messages\": [],\n  \"count\": 0,\n  \"session_id\": \"new_session_123\"\n}\n```\n\n**Existing Session Example:**\n```json\n{\n  \"success\": true,\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello!\",\n      \"created_at\": \"2025-10-23T10:30:00Z\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hi! How can I help?\",\n      \"created_at\": \"2025-10-23T10:30:05Z\"\n    }\n  ],\n  \"count\": 2,\n  \"session_id\": \"session_vqf27hq8x\"\n}\n```\n\n---\n\n### Phase 4: HTTP Response\n**Node:** \"Respond: Return History\"\n**Type:** Respond to Webhook\n**Response Mode:** JSON\n\n**Response Body:**\n```javascript\n={{ $json }}\n```\n(Passes through the normalized object from Code node)\n\n**CORS Headers:**\n```\nAccess-Control-Allow-Origin: *\nAccess-Control-Allow-Methods: POST, GET, OPTIONS\nAccess-Control-Allow-Headers: Content-Type\n```\n\n**Why CORS Matters:**\n- Allows frontend to call from GitHub Pages (different domain)\n- Enables localhost development\n- Supports future deployment scenarios\n\n---\n\n## 5. Frontend Integration\n\n### Chat Module v1.5.0 Implementation\n\n**Endpoint Configuration:**\n```javascript\nthis.endpoints = {\n    // ... other endpoints\n    loadHistory: 'https://n8n.srv997771.hstgr.cloud/webhook/load-conversation-history'\n};\n```\n\n**Backend Loading Function:**\n```javascript\nasync loadConversationHistoryFromBackend(sessionId) {\n    const maxContext = parseInt(localStorage.getItem('cfg_max_context') || '100');\n\n    const response = await this.fetchWithTimeout(this.endpoints.loadHistory, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n            chat_session_id: sessionId,\n            max_context: maxContext\n        })\n    });\n\n    const result = await response.json();\n\n    if (result.success && result.messages) {\n        // Display messages in UI\n        result.messages.forEach(msg => {\n            this.addMessageToUI(msg.role === 'user' ? 'user' : 'ai', msg.content);\n        });\n\n        console.log(`✅ Loaded ${result.count} messages from database`);\n        return true;\n    }\n\n    return false;\n}\n```\n\n**When Called:**\n- On project switch (`switchToChat()`)\n- Before falling back to localStorage\n- Provides true platform-agnostic persistence\n\n---\n\n## 6. Database Schema Reference\n\n### conversation_history Table\n```sql\nCREATE TABLE conversation_history (\n    id SERIAL PRIMARY KEY,\n    session_id VARCHAR(255) NOT NULL,\n    role VARCHAR(50) NOT NULL,  -- 'user' or 'assistant'\n    content TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    INDEX idx_session_created (session_id, created_at)\n);\n```\n\n**Index Strategy:**\n- Composite index on `(session_id, created_at)` optimizes our query\n- Supports fast lookups and chronological ordering\n- Shared with Master Workflow (same table)\n\n---\n\n## 7. Comparison with Master Workflow History\n\n### Master Workflow: \"Get Recent history\"\n- **Purpose:** Immediate context for AI responses\n- **Limit:** Fixed 6 messages\n- **Order:** DESC (newest first, then reversed)\n- **Use Case:** Building prompt context\n- **Scope:** Last few conversational turns\n\n### Load Conversation History: This Workflow\n- **Purpose:** Full conversation display and persistence\n- **Limit:** Configurable (20-100+)\n- **Order:** ASC (oldest first for UI display)\n- **Use Case:** Cross-device chat restoration\n- **Scope:** Complete conversation history\n\n**They complement each other:**\n- Master Workflow: Real-time chat operation\n- This Workflow: Historical retrieval and display\n\n---\n\n## 8. Version History\n\n### v1.1.0 (October 23, 2025) - **CURRENT**\n**Changes:**\n- Added Code normalization node (Phase 3)\n- Prevents `messages: undefined` errors\n- Always returns array structure\n- Better empty session handling\n\n**Fixes:**\n- ✅ Consistent response format\n- ✅ Frontend JSON parsing reliability\n- ✅ Graceful empty result handling\n\n### v1.0.0 (October 22, 2025) - **ARCHIVE**\n**Initial Implementation:**\n- 3-node workflow (Webhook → Postgres → Respond)\n- Basic conversation loading\n- Direct Postgres output (caused undefined issues)\n\n**Why Upgraded:**\n- Empty sessions returned malformed responses\n- Frontend couldn't rely on message array existence\n- v1.1.0 fixes these issues with normalization layer\n\n---\n\n## 9. Testing & Validation\n\n### PowerShell Test Script\n```powershell\n$body = @{\n    chat_session_id = \"session_vqf27hq8x\"\n    max_context = 10\n} | ConvertTo-Json\n\nInvoke-RestMethod -Uri \"https://n8n.srv997771.hstgr.cloud/webhook/load-conversation-history\" `\n    -Method Post `\n    -Body $body `\n    -ContentType \"application/json\"\n```\n\n### Expected Results\n\n**Existing Session:**\n```\nsuccess messages                                          count session_id\n------- --------                                          ----- ----------\n   True {@{role=user; content=Hello!; created_at=...}}       1 session_vqf27hq8x\n```\n\n**Empty/New Session:**\n```\nsuccess messages count session_id\n------- -------- ----- ----------\n   True {}           0 new_session_123\n```\n\n### Browser Console Test\n```javascript\nfetch('https://n8n.srv997771.hstgr.cloud/webhook/load-conversation-history', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n        chat_session_id: 'session_vqf27hq8x',\n        max_context: 50\n    })\n})\n.then(r => r.json())\n.then(data => console.log('✅ Loaded:', data.count, 'messages'))\n```\n\n---\n\n## 10. Troubleshooting Guide\n\n### Problem: Returns 0 messages for existing session\n**Possible Causes:**\n- Wrong `chat_session_id` format\n- Session exists but with different ID pattern\n- Database connection issue\n\n**Debug Steps:**\n1. Check n8n execution log for actual query\n2. Run SQL directly in database:\n   ```sql\n   SELECT DISTINCT session_id FROM conversation_history LIMIT 10;\n   ```\n3. Verify session_id format matches\n\n---\n\n### Problem: \"messages: undefined\" in frontend\n**Cause:** Using v1.0.0 instead of v1.1.0\n\n**Solution:**\n- Import Load_Conversation_History_v1.1.0.json\n- Ensure Code normalization node is present\n- v1.1.0 fixes this issue\n\n---\n\n### Problem: CORS errors from frontend\n**Cause:** Missing CORS headers in Response node\n\n**Solution:**\n- Verify \"Respond: Return History\" node has headers:\n  - `Access-Control-Allow-Origin: *`\n  - `Access-Control-Allow-Methods: POST, GET, OPTIONS`\n  - `Access-Control-Allow-Headers: Content-Type`\n\n---\n\n### Problem: Query timeout with large result sets\n**Cause:** Requesting too many messages (max_context too high)\n\n**Solution:**\n- Limit max_context to reasonable value (100-200)\n- Consider pagination for very large conversations\n- Add database query timeout monitoring\n\n---\n\n## 11. Security Considerations\n\n### Current Implementation\n- **No Authentication:** Endpoint is publicly accessible\n- **Risk Level:** LOW (read-only, no sensitive data modification)\n- **Mitigation:** session_id is non-guessable UUID format\n\n### Future Enhancements\nConsider adding:\n- API key authentication\n- Rate limiting\n- IP whitelisting for production\n- User-specific session access control\n\n---\n\n## 12. Performance Optimization\n\n### Current Performance\n- **Query Time:** ~50-200ms (typical)\n- **Network Time:** ~100-300ms (depends on location)\n- **Total Time:** ~200-500ms end-to-end\n\n### Optimization Strategies\n1. **Database Index:** Already optimized with `(session_id, created_at)` composite index\n2. **LIMIT Clause:** Prevents loading thousands of messages\n3. **Minimal Columns:** Only fetches `role`, `content`, `created_at` (not full row)\n4. **Frontend Caching:** localStorage acts as cache after first load\n\n### Scalability Notes\n- Current design handles 100-1000 sessions easily\n- For 10,000+ sessions, consider:\n  - Connection pooling\n  - Query result caching\n  - CDN for static deployment\n\n---\n\n## 13. Integration with Platform Ecosystem\n\n### Related Components\n\n**Master Chat Workflow:**\n- Writes to same `conversation_history` table\n- Ensures data is available for this workflow to read\n- Creates session_id that this workflow queries\n\n**Chat Module v1.5.0:**\n- Consumes this workflow's API\n- Implements fallback to localStorage\n- Displays loaded messages in UI\n\n**Config Module v1.7:**\n- Provides `cfg_max_context` setting\n- User controls how many messages to load\n- Default: 100 messages\n\n**GitHub Pages Deployment:**\n- Hosts frontend that calls this workflow\n- Enables true cross-device functionality\n- CORS headers make this possible\n\n---\n\n## 14. Success Metrics\n\n### What Success Looks Like\n✅ User opens chat on Computer A\n✅ Conversation saves to database\n✅ User switches to Computer B\n✅ Opens same chat session\n✅ **All messages appear** (loaded from database)\n✅ Can continue conversation seamlessly\n\n### Platform-Agnostic Achievement\n- **Before:** Conversations trapped in browser localStorage\n- **After:** Conversations accessible from any device\n- **Benefit:** True cloud-based chat persistence\n\n---\n\n## 15. API Reference\n\n### Endpoint\n```\nPOST https://n8n.srv997771.hstgr.cloud/webhook/load-conversation-history\n```\n\n### Request Headers\n```\nContent-Type: application/json\n```\n\n### Request Body\n```json\n{\n  \"chat_session_id\": \"string (required)\",\n  \"max_context\": \"number (optional, default: 100)\"\n}\n```\n\n### Response Format\n```json\n{\n  \"success\": true,\n  \"session_id\": \"string\",\n  \"count\": \"number\",\n  \"messages\": [\n    {\n      \"role\": \"user|assistant\",\n      \"content\": \"string\",\n      \"created_at\": \"ISO 8601 timestamp\"\n    }\n  ]\n}\n```\n\n### HTTP Status Codes\n- `200 OK`: Success (even if 0 messages)\n- `400 Bad Request`: Missing required parameters\n- `500 Internal Server Error`: Database/workflow error\n\n---\n\n## 16. Deployment Checklist\n\nBefore deploying to production canvas:\n\n- [ ] Import Load_Conversation_History_v1.1.0.json to n8n\n- [ ] Verify Postgres credentials are set\n- [ ] Test with PowerShell (existing session)\n- [ ] Test with PowerShell (empty session)\n- [ ] Activate workflow in n8n\n- [ ] Copy webhook URL for frontend\n- [ ] Update frontend endpoint configuration\n- [ ] Test from localhost browser\n- [ ] Deploy to GitHub Pages\n- [ ] Test from second computer\n- [ ] Verify cross-device persistence works\n- [ ] Attach this documentation to canvas workflow\n- [ ] Download complete canvas for version control\n\n---\n\n**Documentation Generated:** October 23, 2025\n**Workflow Version:** v1.1.0\n**Status:** Production Ready ✅\n\n🤖 *Generated with Claude Code (https://claude.com/claude-code)*\n*Co-Authored-By: Claude <noreply@anthropic.com>*\n",
        "height": 80,
        "width": 352
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -3456,
        -3024
      ],
      "typeVersion": 1,
      "id": "3761dc78-ecb1-419b-bc7b-3513aa3cac3a",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "update-project-info",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -3680,
        -3360
      ],
      "id": "21a4040c-9137-48f3-9964-d2c4c948947e",
      "name": "Webhook: Update Project Trigger",
      "webhookId": "update-project-info"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE project_contexts \nSET project_name = $1, description = $2 \nWHERE chat_session_id = $3\nRETURNING project_name, description, chat_session_id;",
        "options": {
          "queryReplacement": "={{ [$json.body.project_name, $json.body.description, $json.body.chat_session_id] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3456,
        -3360
      ],
      "id": "6063db1f-a830-4764-bb40-509a23f685ae",
      "name": "Postgres: Update Project",
      "credentials": {
        "postgres": {
          "id": "wnjdz7ukUBDZySLN",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              },
              {
                "name": "Access-Control-Allow-Methods",
                "value": "POST, OPTIONS"
              },
              {
                "name": "Access-Control-Allow-Headers",
                "value": "Content-Type"
              }
            ]
          }
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        -3008,
        -3360
      ],
      "id": "3aeb9afa-d788-4f03-8263-6d2745e51e03",
      "name": "Respond: Return Result"
    },
    {
      "parameters": {
        "content": "## Update Project Info Workflow\n\n\n**Purpose:** Updates project name and description in project_contexts table\n\n**Endpoint:** POST /webhook/update-project-info\n\n**Input:**\n```json\n{\n  \"chat_session_id\": \"session_xyz\",\n  \"project_name\": \"New Name\",\n  \"description\": \"New Description\"\n}\n```\n\n**Output:**\n```json\n{\n  \"success\": true,\n  \"project_name\": \"New Name\",\n  \"description\": \"New Description\",\n  \"chat_session_id\": \"session_xyz\"\n}\n```\n\n**Notes:**\n- Uses chat_session_id as immutable lookup key\n- Only updates project_name and description fields\n- Returns error if project not found\n- CORS enabled for GitHub Pages access",
        "height": 80,
        "width": 384
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -3488,
        -3488
      ],
      "typeVersion": 1,
      "id": "9b2440bc-0168-41e8-b573-2d65ab59345a",
      "name": "Sticky Note: Documentation"
    },
    {
      "parameters": {
        "jsCode": "// Normalize response from Postgres update\nconst items = $input.all();\n\n// Check if update was successful (returned rows)\nif (items.length === 0) {\n  return [{\n    json: {\n      success: false,\n      error: \"Project not found or update failed\",\n      chat_session_id: $('Webhook: Update Project Trigger').first().json.body.chat_session_id\n    }\n  }];\n}\n\n// Extract updated project info\nconst updatedProject = items[0].json;\n\nreturn [{\n  json: {\n    success: true,\n    project_name: updatedProject.project_name,\n    description: updatedProject.description,\n    chat_session_id: updatedProject.chat_session_id\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3248,
        -3360
      ],
      "id": "78bbcd2f-dec1-466f-9177-6025533e763a",
      "name": "Code: Normalize Response1"
    }
  ],
  "pinData": {
    "Trigger: Receive Session ID": [
      {
        "json": {
          "headers": {
            "host": "mhcmike.app.n8n.cloud",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
            "content-length": "3128",
            "accept": "application/json",
            "accept-encoding": "gzip, br",
            "accept-language": "en-US,en;q=0.9",
            "cdn-loop": "cloudflare; loops=1; subreqs=1",
            "cf-connecting-ip": "72.219.130.70",
            "cf-ew-via": "15",
            "cf-ipcountry": "US",
            "cf-ray": "97aefde2651d0fb8-LAX",
            "cf-visitor": "{\"scheme\":\"https\"}",
            "cf-worker": "n8n.cloud",
            "content-type": "application/json",
            "origin": "http://127.0.0.1:5500",
            "priority": "u=1, i",
            "referer": "http://127.0.0.1:5500/",
            "sec-ch-ua": "\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"",
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "\"Windows\"",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "cross-site",
            "x-forwarded-for": "72.219.130.70, 172.70.210.225",
            "x-forwarded-host": "mhcmike.app.n8n.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "traefik-prod-users-gwc-34-f494454b5-f88k9",
            "x-is-trusted": "yes",
            "x-real-ip": "72.219.130.70"
          },
          "params": {},
          "query": {},
          "body": {
            "chat_session_id": "session_6ige5bcxg",
            "project_id": "rec_d2u53dtqrj67jthrfi0g",
            "rag_session_id": "8d6becfa-d861-45c9-ac43-2078e93ef3fa",
            "history": [
              {
                "role": "assistant",
                "content": "Project \"9/6/25 Test 1\" created successfully. Persona: Developer Assistant (A)."
              },
              {
                "role": "user",
                "content": "Hello my name is mike. I'm doing some testing this morning. I'll be making some statements and then adding them to a memory function I have designed. I'll close this session, restart it and see if you can remember these statements. Are you ready?"
              },
              {
                "role": "assistant",
                "content": "Hello Mike! Yes, I'm ready to help with your testing.\nJust to set clear expectations: I don't have the ability to retain information between separate chat sessions on my own. Each time you start a new conversation with me, I begin with a fresh slate and no memory of previous interactions.\nHowever, I understand you're testing a memory function you've designed, which sounds like it might work by:\n\nStoring information from our current session\nMaking that information available to me in future sessions (perhaps through the knowledge base context)\n\nI'm ready to participate in your test! Feel free to share the statements you'd like to test with your memory system.\nmodel?"
              },
              {
                "role": "user",
                "content": "Here we go...my truck is blue"
              },
              {
                "role": "assistant",
                "content": "Got it, Mike! I've noted that your truck is blue.\nI'm ready for any additional statements you'd like to share for your memory function testing. Just let me know when you have more information to add or when you're ready to move to the next phase of your test.\nmodel?"
              },
              {
                "role": "user",
                "content": "the truck is a Ford F350"
              },
              {
                "role": "assistant",
                "content": "Perfect! I've now noted:\n\nYour truck is blue\nYour truck is a Ford F350\n\nSo you have a blue Ford F350. Got it recorded for your memory function test!\nReady for any additional statements or whenever you're ready to proceed to the next phase of testing.\nmodel?"
              },
              {
                "role": "user",
                "content": "I have a green fan on my desk"
              },
              {
                "role": "assistant",
                "content": "Noted, Mike! I now have these details recorded for your memory function test:\n\nYour truck is blue\nYour truck is a Ford F350 \nYou have a green fan on your desk\n\nThree pieces of information logged! Ready for more statements or whenever you want to move to the next phase of your memory system testing.\nmodel?"
              },
              {
                "role": "user",
                "content": "ok, thanks. I'm going to commit this session to memory (a RAG Vector database), stop/restart and check if you can remember."
              },
              {
                "role": "assistant",
                "content": "Sounds good, Mike! I understand you're testing your memory system by:\n\nCommitting this session to your RAG Vector database\nStopping/restarting the system\nTesting recall to see if I can remember the details we discussed\n\nThe information we covered for your test:\n\nYour truck is blue\nYour truck is a Ford F350\nYou have a green fan on your desk\n\nGo ahead and run your commit process. I'll be ready to demonstrate whether the memory system successfully retrieves this information when you restart and test recall!\nmodel?"
              }
            ],
            "database_branch": "main",
            "xata_branch": "main"
          },
          "webhookUrl": "https://mhcmike.app.n8n.cloud/webhook/6c1ce608-2f7a-457b-9afc-f0be5ef4bd4c",
          "executionMode": "production"
        }
      }
    ],
    "Webhook3": [
      {
        "json": {
          "headers": {
            "host": "n8n.srv997771.hstgr.cloud",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
            "content-length": "72",
            "accept": "*/*",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "en-US,en;q=0.9",
            "cache-control": "no-cache",
            "content-type": "application/json",
            "origin": "http://127.0.0.1:5500",
            "pragma": "no-cache",
            "priority": "u=1, i",
            "referer": "http://127.0.0.1:5500/",
            "sec-ch-ua": "\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"",
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "\"Windows\"",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "cross-site",
            "x-forwarded-for": "72.219.130.70",
            "x-forwarded-host": "n8n.srv997771.hstgr.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "0e4effe4917a",
            "x-real-ip": "72.219.130.70"
          },
          "params": {},
          "query": {},
          "body": {
            "action": "list_projects",
            "database_branch": "main",
            "xata_branch": "main"
          },
          "webhookUrl": "https://n8n.srv997771.hstgr.cloud/webhook/a61a290c-d8e5-4c04-980a-4ebb415a21e4",
          "executionMode": "production"
        }
      }
    ],
    "Webhook": [
      {
        "json": {
          "headers": {
            "host": "n8n.srv997771.hstgr.cloud",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
            "content-length": "108",
            "accept": "*/*",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "en-US,en;q=0.9",
            "content-type": "application/json",
            "origin": "http://127.0.0.1:5500",
            "priority": "u=1, i",
            "referer": "http://127.0.0.1:5500/",
            "sec-ch-ua": "\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"",
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "\"Windows\"",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "cross-site",
            "x-forwarded-for": "72.219.130.70",
            "x-forwarded-host": "n8n.srv997771.hstgr.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "0e4effe4917a",
            "x-real-ip": "72.219.130.70"
          },
          "params": {},
          "query": {},
          "body": {
            "projectName": "9/8/25 Test v1",
            "persona_key": "dev_assistant",
            "database_branch": "main",
            "xata_branch": "main"
          },
          "webhookUrl": "https://n8n.srv997771.hstgr.cloud/webhook/d0b91f11-487b-441f-80a3-17edd5a703db",
          "executionMode": "production"
        }
      }
    ],
    "Webhook2": [
      {
        "json": {
          "headers": {
            "host": "n8n.srv997771.hstgr.cloud",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
            "content-length": "157",
            "accept": "*/*",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "en-US,en;q=0.9",
            "content-type": "application/json",
            "origin": "http://127.0.0.1:5500",
            "priority": "u=1, i",
            "referer": "http://127.0.0.1:5500/",
            "sec-ch-ua": "\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"",
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "\"Windows\"",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "cross-site",
            "x-forwarded-for": "72.219.130.70",
            "x-forwarded-host": "n8n.srv997771.hstgr.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "0e4effe4917a",
            "x-real-ip": "72.219.130.70"
          },
          "params": {},
          "query": {},
          "body": {
            "projectName": "9/8/25 Test Bob 700k v2",
            "jsonUrl": "https://storage.googleapis.com/mhcmike-ai-chat-interface/Bob_Original_700k.json",
            "persona_key": "bob_mhc"
          },
          "webhookUrl": "https://n8n.srv997771.hstgr.cloud/webhook/303639ed-a3e2-4eae-b406-16e1c6200a81",
          "executionMode": "production"
        }
      }
    ],
    "AI Router Webhook": [
      {
        "json": {
          "headers": {
            "host": "n8n.srv997771.hstgr.cloud",
            "user-agent": "axios/1.8.3",
            "content-length": "3960",
            "accept": "application/json,text/html,application/xhtml+xml,application/xml,text/*;q=0.9, image/*;q=0.8, */*;q=0.7",
            "accept-encoding": "gzip, compress, deflate, br",
            "content-type": "application/json",
            "x-forwarded-for": "172.18.0.1",
            "x-forwarded-host": "n8n.srv997771.hstgr.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "0910137f0700",
            "x-real-ip": "172.18.0.1"
          },
          "params": {},
          "query": {},
          "body": {
            "selected_model": "claude-4-sonnet",
            "messages": [
              {
                "role": "system",
                "content": "You are Bob, a helpful and knowledgeable AI assistant.\n\n--- Relevant Knowledge Base Context ---\n--- CONTEXT FROM KNOWLEDGE BASE ---\n{\n    \"facts\": [\n        \"The user is conducting a test on their modified user interface, which now preserves session dialogue content.\",\n        \"The user described a system utilizing a 'commit to memory' button that activates when there's conversation content in the chat.\",\n        \"The user explained a RAG (Retrieval-Augmented Generation) system involving 'conversation_history' and 'rag_store' tables to manage conversation continuity and context.\"\n    ]\n}\n\nFormatting rules: Use Markdown. Prefer short sections with headings when helpful. Use bullet lists for lists. Bold short labels. Use tables only when clearly beneficial. Keep responses concise and scannable."
              },
              {
                "role": "user",
                "content": "**I'm Claude 3.5 Sonnet** - but I don't have access to my specific version number or build details from my current context.\n\n**What I can tell you:**\n- **Model family:** Claude 3.5 Sonnet (Anthropic)\n- **Capabilities:** Text, image analysis, code, reasoning\n- **Version specifics:** Not visible to me in this session\n\n**To get exact version info, you'd need to:**\n- Check your API configuration/dashboard\n- Look at request headers if using API\n- Check the platform documentation where you're running me\n\n**For your testing purposes:** I'm consistently handling your image uploads and analysis without issues, regardless of the specific build version.\n\n**Ready to continue the image testing sequence!**"
              },
              {
                "role": "user",
                "content": "OK Bob here's another image coming at you"
              },
              {
                "role": "user",
                "content": "**Test Image #4 - Labrador Retriever:**\n\n**Features:**\n- **Golden coat** - classic Labrador color\n- **Outdoor scene** - standing on beach with mountains in background\n- **Alert posture** - focused and attentive\n- **Natural lighting** - soft, even tones\n\n**Technical status:**\n- **Upload:** Successful\n- **Display:** Clean render\n- **Quality:** Excellent detail\n- **UI:** No issues detected\n\n**Everything's looking great!** Let me know when you're ready for the next one or if anything specific needs attention."
              },
              {
                "role": "user",
                "content": "Please tell me your model and version number"
              },
              {
                "role": "user",
                "content": "I currently don't have access to my specific model version number or build details within this session. However, I operate under the **Claude 3.5 Sonnet** model family, developed by Anthropic. For precise version details:\n\n- **Check your API interface/dashboard** if applicable.\n- **Review request headers** of your API calls.\n- **Consult your platform documentation** if you're using a specific service to run these tests.\n\nIf there's anything else you need or any specific issues arise during your image tests, feel free to let me know!"
              },
              {
                "role": "user",
                "content": ""
              },
              {
                "role": "user",
                "content": [
                  {
                    "type": "text",
                    "text": ""
                  },
                  {
                    "type": "image_url",
                    "image_url": {
                      "url": "https://storage.googleapis.com/mhcmike-ai-chat-interface/Images/general/unknown/2025-09-28T19%3A50%3A08.998Z_2025-09-28_12-50-05.PNG?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=vertex-ai-user-for-n8n%40persistant-ai-chat.iam.gserviceaccount.com%2F20250928%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250928T195009Z&X-Goog-Expires=3600&X-Goog-SignedHeaders=host&X-Goog-Signature=52a421c21c8fe2e0619c456ea1fdcb80e88bb6ce1045973bbab569170a7f64718708e095c5639071e8b9385f9ca9adb94ac215641ef69ee0dbc7cb88f24b260849911c855e2cdfd3fee5bc8c2d069bec513ed838551a1748347a73d22f417ec52028f5a2fb43734e4e1d4cd00a52ddb2efcc1eb58f4176a407e4431b4de4748f11b1b4961bd645cd2fbaa5db19af0a6a0b80933e081fdf98b9e2384dbf2bf0e81b0da91a42035414136207ae8e92d4e8ea106961a06e168f0146ebce48c12944c51253e0aa434b91549eb576e5a7508d3c88f8baf630005a7d12cce4d0c9c5eb89806d63d98f6999a5e662d0ed269d335da60fdf856b5b27428d579406566135",
                      "detail": "auto"
                    }
                  }
                ]
              }
            ]
          },
          "webhookUrl": "https://n8n.srv997771.hstgr.cloud/webhook/ai-router",
          "executionMode": "production"
        }
      }
    ],
    "Webhook1": [],
    "Webhook: Load History Trigger": [
      {
        "json": {
          "headers": {
            "host": "n8n.srv997771.hstgr.cloud",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "content-length": "56",
            "accept": "*/*",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "en-US,en;q=0.9",
            "content-type": "application/json",
            "origin": "https://mxmike508.github.io",
            "priority": "u=1, i",
            "referer": "https://mxmike508.github.io/",
            "sec-ch-ua": "\"Google Chrome\";v=\"141\", \"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"141\"",
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "\"Windows\"",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "cross-site",
            "x-forwarded-for": "72.219.130.70",
            "x-forwarded-host": "n8n.srv997771.hstgr.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "0910137f0700",
            "x-real-ip": "72.219.130.70"
          },
          "params": {},
          "query": {},
          "body": {
            "chat_session_id": "session_33tp9y2pl",
            "max_context": 20
          },
          "webhookUrl": "https://n8n.srv997771.hstgr.cloud/webhook/load-conversation-history",
          "executionMode": "production"
        }
      }
    ]
  },
  "connections": {
    "DB: Get Conversation History": {
      "main": [
        [
          {
            "node": "Calculate New High-Water Mark",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format: Assemble Transcript": {
      "main": [
        [
          {
            "node": "Build: OpenAI Request Body",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build: OpenAI Request Body": {
      "main": [
        [
          {
            "node": "Execute: OpenAI API Call",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute: OpenAI API Call": {
      "main": [
        [
          {
            "node": "Set: Extracted Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "DB: Get High-Water Mark": {
      "main": [
        [
          {
            "node": "Set: Watermark Value",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set: Watermark Value": {
      "main": [
        [
          {
            "node": "DB: Get Conversation History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set: Extracted Summary": {
      "main": [
        [
          {
            "node": "Chunk: Distilled Summary",
            "type": "main",
            "index": 0
          },
          {
            "node": "Count Facts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Count Facts": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Chunk: Distilled Summary": {
      "main": [
        [
          {
            "node": "API: Create Embeddings (HTTP) node",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "DB: Insert Embedding1": {
      "main": [
        [
          {
            "node": "DB: Update High-Water Mark",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "DB: Update High-Water Mark": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF: New Messages Found?": {
      "main": [
        [
          {
            "node": "Format: Assemble Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate New High-Water Mark": {
      "main": [
        [
          {
            "node": "IF: New Messages Found?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "API: Create Embeddings (HTTP) node": {
      "main": [
        [
          {
            "node": "Merge Embedding with Original Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Embedding with Original Data": {
      "main": [
        [
          {
            "node": "DB: Insert Embedding1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Project ID": {
      "main": [
        [
          {
            "node": "DB: Get High-Water Mark",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Trigger: Receive Session ID": {
      "main": [
        [
          {
            "node": "Get Project ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Respond to Webhook6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres1": {
      "main": [
        [
          {
            "node": "Respond to Webhook5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Project List": {
      "main": [
        [
          {
            "node": "If1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code2": {
      "main": [
        [
          {
            "node": "Postgres1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If1": {
      "main": [
        [
          {
            "node": "Code3",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook3": {
      "main": [
        [
          {
            "node": "Get Project List",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code3": {
      "main": [
        [
          {
            "node": "Respond to Webhook4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Check if Project Exists",
            "type": "main",
            "index": 0
          },
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres": {
      "main": [
        [
          {
            "node": "Generate Thread ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Postgres",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Success Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Thread ID": {
      "main": [
        [
          {
            "node": "Save Thread ID to Project",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Thread ID to Project": {
      "main": [
        [
          {
            "node": "Prepare Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Embedding1": {
      "main": [
        [
          {
            "node": "Merge Embedding with Chunk Data1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Format Vector for Postgres1": {
      "main": [
        [
          {
            "node": "Insert Embedding to Xata1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert Embedding to Xata1": {
      "main": [
        [
          {
            "node": "Prepare Final Response1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for DB1": {
      "main": [
        [
          {
            "node": "Format Vector for Postgres1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request GCS Fetch1": {
      "main": [
        [
          {
            "node": "Chunk Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunk Code1": {
      "main": [
        [
          {
            "node": "Filter1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Embedding with Chunk Data1": {
      "main": [
        [
          {
            "node": "Prepare for DB1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter1": {
      "main": [
        [
          {
            "node": "Create Embedding1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge Embedding with Chunk Data1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Project Entry1": {
      "main": [
        [
          {
            "node": "HTTP Request GCS Fetch1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Final Response1": {
      "main": [
        [
          {
            "node": "Respond to Webhook3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook2": {
      "main": [
        [
          {
            "node": "Create Project Entry1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request to AI Router": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "Postgres2 (Save AI Reply)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Respond to Webhook2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format History for AI": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Query Embedding": {
      "main": [
        [
          {
            "node": "Format Data for Vector Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Data for Vector Search": {
      "main": [
        [
          {
            "node": "Retrieve Committed Memory",
            "type": "main",
            "index": 0
          },
          {
            "node": "Retrieve RAG Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Session ID & Input": {
      "main": [
        [
          {
            "node": "Save User Message to History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Recent history": {
      "main": [
        [
          {
            "node": "Format Recent History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Recent History": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Save User Message to History": {
      "main": [
        [
          {
            "node": "Preserve Current Inputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Preserve Current Inputs": {
      "main": [
        [
          {
            "node": "Format Current Input",
            "type": "main",
            "index": 0
          },
          {
            "node": "If Rag is Active",
            "type": "main",
            "index": 0
          },
          {
            "node": "Config: Auto-Commit Enabled",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Config: Auto-Commit Enabled": {
      "main": [
        [
          {
            "node": "If Remember Intent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Remember Intent": {
      "main": [
        [
          {
            "node": "Auto Commit via Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RAG Context consolidator": {
      "main": [
        [
          {
            "node": "Format History for AI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Build OpenAI Payload1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Current Input": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Build OpenAI Payload1": {
      "main": [
        [
          {
            "node": "HTTP Request to AI Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Rag is Active": {
      "main": [
        [
          {
            "node": "Create Query Embedding",
            "type": "main",
            "index": 0
          },
          {
            "node": "Get Recent history",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Get Recent history",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Retrieve Committed Memory": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Retrieve RAG Chunks": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "RAG Context consolidator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook1": {
      "main": [
        [
          {
            "node": "Pre-flight Request",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Get Session ID & Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Router Webhook": {
      "main": [
        [
          {
            "node": "Input Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Input Processor": {
      "main": [
        [
          {
            "node": "Provider Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Provider Check": {
      "main": [
        [
          {
            "node": "Claude Preprocessor",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenAI Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Request": {
      "main": [
        [
          {
            "node": "OpenAI Normalizer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude Preprocessor": {
      "main": [
        [
          {
            "node": "Claude Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude Request": {
      "main": [
        [
          {
            "node": "Claude Normalizer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Normalizer": {
      "main": [
        [
          {
            "node": "Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude Normalizer": {
      "main": [
        [
          {
            "node": "Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook: Load History Trigger": {
      "main": [
        [
          {
            "node": "Postgres: Get Conversation History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Get Conversation History": {
      "main": [
        [
          {
            "node": "Code: Normalize Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code: Normalize Response": {
      "main": [
        [
          {
            "node": "Respond: Return History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook: Update Project Trigger": {
      "main": [
        [
          {
            "node": "Postgres: Update Project",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Update Project": {
      "main": [
        [
          {
            "node": "Code: Normalize Response1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code: Normalize Response1": {
      "main": [
        [
          {
            "node": "Respond: Return Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner"
  },
  "versionId": "ad96b094-4688-4f0d-8ac6-3fba312d718a",
  "meta": {
    "instanceId": "8fe1de58704fdaeb90ba65ff6b0aed2cf5efcb6cafc89641fb03be73646f227e"
  },
  "id": "x4nTj9PQcuCWzwta",
  "tags": []
}