{
  "name": "AI Router v1.4 w/credentials",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ai-router",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        1140,
        -460
      ],
      "id": "929033dd-0cb7-4e95-92bb-04b4e0e07962",
      "name": "AI Router Webhook",
      "webhookId": "959cc516-c1a0-484c-9fe9-86ef40690e14"
    },
    {
      "parameters": {
        "jsCode": "// AI Router Input Processor\nvar body = $json.body || $json || {};\nvar selectedModel = body.selected_model || body.model || 'gpt-4o';\nvar messages = body.messages || [];\n\n// Determine if this is a Claude model - be very specific\nvar modelLower = selectedModel.toLowerCase();\nvar isClaudeModel = modelLower.includes('claude-') || modelLower.startsWith('claude');\n\n// For GPT models, ensure they are NOT Claude\nif (modelLower.includes('gpt') || modelLower.includes('openai')) {\n  isClaudeModel = false;\n}\n\n// Debug logging\nconsole.log('=== AI Router Debug ===');\nconsole.log('Selected Model:', selectedModel);\nconsole.log('Model Lower:', modelLower);\nconsole.log('Is Claude Model:', isClaudeModel);\nconsole.log('Expected Path:', isClaudeModel ? 'Claude' : 'OpenAI');\n\nreturn {\n  selectedModel: selectedModel,\n  messages: messages,\n  isClaudeModel: isClaudeModel,\n  originalPayload: body,\n  debug: {\n    selectedModel: selectedModel,\n    isClaudeModel: isClaudeModel,\n    modelLower: modelLower,\n    expectedPath: isClaudeModel ? 'Claude' : 'OpenAI'\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1340,
        -460
      ],
      "id": "4ca4f995-667a-4e03-bd15-c81a93e3e9f4",
      "name": "Input Processor"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": false,
            "leftValue": "",
            "typeValidation": "loose"
          },
          "conditions": [
            {
              "id": "claude-check",
              "leftValue": "={{ $json.selectedModel }}",
              "rightValue": "claude",
              "operator": {
                "type": "string",
                "operation": "contains",
                "caseSensitive": false
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1540,
        -460
      ],
      "id": "5db55c07-a73a-4400-ab49-d8827383ad81",
      "name": "Provider Check"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"model\": $json.selectedModel, \"messages\": $json.messages, \"max_tokens\": 4000 } }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1740,
        -560
      ],
      "id": "4e08be85-9f6f-4023-8544-038685948b16",
      "name": "OpenAI Request",
      "credentials": {
        "openAiApi": {
          "id": "coeze5tlOwYaVsLb",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare Claude payload with CURRENT model mapping (2025)\nvar originalPayload = $json.originalPayload || {};\nvar messages = $json.messages || [];\nvar selectedModel = $json.selectedModel;\n\n// Map frontend model names to CURRENT Claude API model identifiers (2025)\nvar claudeModelMap = {\n  'claude-3.5-sonnet': 'claude-sonnet-4-20250514',\n  'claude-3-5-sonnet': 'claude-sonnet-4-20250514',\n  'claude-3-opus': 'claude-opus-4-20250514',\n  'claude-3-sonnet': 'claude-sonnet-4-20250514',\n  'claude-3-haiku': 'claude-3-5-haiku-20241022'\n};\n\n// Get the correct Claude API model identifier\nvar claudeApiModel = claudeModelMap[selectedModel] || 'claude-sonnet-4-20250514';\n\nconsole.log('=== Claude Preprocessor Debug (2025 Models) ===');\nconsole.log('Frontend Model:', selectedModel);\nconsole.log('Mapped Claude Model:', claudeApiModel);\n\n// Convert OpenAI format to Claude format\nvar systemMessage = '';\nvar filteredMessages = [];\n\nfor (var i = 0; i < messages.length; i++) {\n  if (messages[i].role === 'system') {\n    systemMessage = messages[i].content || '';\n  } else {\n    filteredMessages.push({\n      role: messages[i].role,\n      content: messages[i].content\n    });\n  }\n}\n\nvar claudePayload = {\n  model: claudeApiModel,\n  max_tokens: originalPayload.max_tokens || 4000,\n  messages: filteredMessages\n};\n\nif (systemMessage) {\n  claudePayload.system = systemMessage;\n}\n\nconsole.log('Final Claude Payload (2025):', JSON.stringify(claudePayload, null, 2));\n\nreturn {\n  claudePayload: claudePayload,\n  selectedModel: selectedModel,\n  claudeApiModel: claudeApiModel\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1740,
        -360
      ],
      "id": "74c3f3d3-45ec-4889-8695-e7130d7179e9",
      "name": "Claude Preprocessor"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.claudePayload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1940,
        -360
      ],
      "id": "54ca2226-19d4-4d2c-a7bd-c7bd50e975cb",
      "name": "Claude Request",
      "credentials": {
        "httpHeaderAuth": {
          "id": "Q1bPQWGLKj2te1lT",
          "name": "OpenAI Header Auth"
        },
        "anthropicApi": {
          "id": "Ql5vCdabLoTNwj0q",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Normalize OpenAI Response\nvar response = $json;\nvar selectedModel = 'unknown';\n\n// Try to get the selected model from the input processor\ntry {\n  var inputProcessorData = $('Input Processor').first();\n  if (inputProcessorData && inputProcessorData.json) {\n    selectedModel = inputProcessorData.json.selectedModel || 'unknown';\n  }\n} catch(e) {\n  // Fallback: try to get from response or use default\n  selectedModel = response.model || 'gpt-4o';\n}\n\nvar normalizedResponse = {};\n\nif (response.choices && response.choices[0] && response.choices[0].message) {\n  normalizedResponse = {\n    success: true,\n    provider: 'openai',\n    model: selectedModel,\n    content: response.choices[0].message.content,\n    usage: response.usage || {}\n  };\n} else {\n  normalizedResponse = {\n    success: false,\n    provider: 'openai',\n    model: selectedModel,\n    error: 'Invalid OpenAI response format',\n    raw_response: response\n  };\n}\n\nreturn normalizedResponse;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1940,
        -560
      ],
      "id": "db5bc1a2-6350-45c5-b9b5-920584d4c2fd",
      "name": "OpenAI Normalizer"
    },
    {
      "parameters": {
        "jsCode": "// Normalize Claude Response\nvar response = $json;\nvar selectedModel = 'unknown';\nvar displayModel = 'claude-sonnet-4';\n\n// Try to get the selected model from the claude preprocessor\ntry {\n  var claudeData = $('Claude Preprocessor').first();\n  if (claudeData && claudeData.json) {\n    selectedModel = claudeData.json.selectedModel || 'unknown';\n    var claudeApiModel = claudeData.json.claudeApiModel;\n    \n    // Use a clean display name based on the API model\n    if (claudeApiModel && claudeApiModel.includes('claude-sonnet-4')) {\n      displayModel = 'claude-sonnet-4';\n    } else if (claudeApiModel && claudeApiModel.includes('claude-opus-4')) {\n      displayModel = 'claude-opus-4';\n    } else {\n      displayModel = selectedModel; // fallback to frontend name\n    }\n  }\n} catch(e) {\n  // Fallback: use default claude model\n  selectedModel = 'claude-3-5-sonnet';\n  displayModel = 'claude-sonnet-4';\n}\n\nconsole.log('=== Claude Normalizer Debug ===');\nconsole.log('Frontend Model:', selectedModel);\nconsole.log('Display Model:', displayModel);\n\nvar normalizedResponse = {};\n\nif (response.content && response.content[0] && response.content[0].text) {\n  normalizedResponse = {\n    success: true,\n    provider: 'claude',\n    model: displayModel,\n    content: response.content[0].text,\n    usage: response.usage || {}\n  };\n} else {\n  normalizedResponse = {\n    success: false,\n    provider: 'claude',\n    model: displayModel,\n    error: 'Invalid Claude response format',\n    raw_response: response\n  };\n}\n\nreturn normalizedResponse;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2140,
        -360
      ],
      "id": "a46729ed-cff3-4678-8544-3cd3205796a2",
      "name": "Claude Normalizer"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        2340,
        -460
      ],
      "id": "3c4e10b5-a6ef-499f-8ccf-b0ed9eb19b3c",
      "name": "Response"
    }
  ],
  "pinData": {
    "AI Router Webhook": [
      {
        "json": {
          "headers": {
            "host": "mhcmike.app.n8n.cloud",
            "user-agent": "axios/1.8.2",
            "content-length": "1926",
            "accept": "application/json,text/html,application/xhtml+xml,application/xml,text/*;q=0.9, image/*;q=0.8, */*;q=0.7",
            "accept-encoding": "gzip, br",
            "cdn-loop": "cloudflare; loops=1; subreqs=1",
            "cf-connecting-ip": "20.218.238.124",
            "cf-ew-via": "15",
            "cf-ipcountry": "DE",
            "cf-ray": "9735bafd21062c4e-FRA",
            "cf-visitor": "{\"scheme\":\"https\"}",
            "cf-worker": "n8n.cloud",
            "content-type": "application/json",
            "x-forwarded-for": "20.218.238.124, 172.71.250.74",
            "x-forwarded-host": "mhcmike.app.n8n.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "traefik-prod-users-gwc-34-f494454b5-f88k9",
            "x-is-trusted": "yes",
            "x-real-ip": "20.218.238.124"
          },
          "params": {},
          "query": {},
          "body": {
            "model": "claude-3.5-sonnet",
            "messages": [
              {
                "role": "system",
                "content": "You are Bob, a helpful and knowledgeable AI assistant.\n\n--- Relevant Knowledge Base Context ---\n--- CONTEXT FROM KNOWLEDGE BASE ---\n{\n  \"facts\": [\n    \"Potential Gross Profit margins are relatively constant across months but decrease in March and April.\",\n    \"There is a consistent negative reserve balance of $534,167 every month.\",\n    \"Labor costs are highest in January and August.\",\n    \"Net Operating Income (NOI) is lowest in August ($111,246) and highest in December ($-30,974).\",\n    \"Net Operating Income and NOI + Reserve exhibit a growing trend over the year, peaking in December.\",\n    \"The number of projects is mostly consistent around 5 to 7.\",\n    \"An n8n workflow that is MCP compatible can interact with other MCP-compatible tools.\",\n    \"MCP compatibility allows interoperability, scalability, efficiency, and flexibility between tools.\",\n    \"Assistant is based on OpenAI's language model technology, specifically GPT-4, last trained up to October 2023.\",\n    \"The user's truck color is blue.\"\n  ]\n}\n\nFormatting rules: Use Markdown. Prefer short sections with headings when helpful. Use bullet lists for lists. Bold short labels. Use tables only when clearly beneficial. Keep responses concise and scannable."
              },
              {
                "role": "user",
                "content": "MN:OnAIGPT4LtTrnnDt:Otr2023"
              },
              {
                "role": "user",
                "content": "tell me your model name and your version number"
              },
              {
                "role": "user",
                "content": "tell me your model name and version number"
              },
              {
                "role": "user",
                "content": "tell me your model name and version number"
              },
              {
                "role": "user",
                "content": "tell me your model name and version number"
              },
              {
                "role": "user",
                "content": "tell me your model name and version number"
              },
              {
                "role": "user",
                "content": "tell me your model name and version number"
              }
            ],
            "usedVision": false,
            "frontendModel": "claude-3.5-sonnet",
            "modelType": "claude",
            "routeTo": "claude"
          },
          "webhookUrl": "https://mhcmike.app.n8n.cloud/webhook/ai-router",
          "executionMode": "production"
        }
      }
    ]
  },
  "connections": {
    "AI Router Webhook": {
      "main": [
        [
          {
            "node": "Input Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Input Processor": {
      "main": [
        [
          {
            "node": "Provider Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Provider Check": {
      "main": [
        [
          {
            "node": "Claude Preprocessor",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenAI Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Request": {
      "main": [
        [
          {
            "node": "OpenAI Normalizer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude Preprocessor": {
      "main": [
        [
          {
            "node": "Claude Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude Request": {
      "main": [
        [
          {
            "node": "Claude Normalizer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Normalizer": {
      "main": [
        [
          {
            "node": "Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude Normalizer": {
      "main": [
        [
          {
            "node": "Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "b9a752cd-2037-4edd-b68d-d1a855e41d69",
  "meta": {
    "instanceId": "c4c30886ead33627446590bc73a5bef82db63d1121e51ff9b9b6f6ea92a27ca3"
  },
  "id": "CNy24G0THuG5rsA6",
  "tags": []
}